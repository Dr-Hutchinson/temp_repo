{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "title"
    ]
   },
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    " ### Contributor1FirstName  Contributor1LastName [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/ORCID_ID) \n",
    "Institution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Contributor2FirstName  Contributor2LastName [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/ORCID_ID_IF_EXIST) \n",
    "Institution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "contributor"
    ]
   },
   "source": [
    "### Contributor3FirstName  Contributor3LastName [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/ORCID_ID_IF_EXIST) \n",
    "Institution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "copyright"
    ]
   },
   "source": [
    "[![cc-by](https://licensebuttons.net/l/by/4.0/88x31.png)](https://creativecommons.org/licenses/by/4.0/) \n",
    "©<AUTHOR or ORGANIZATION / FUNDER>. Published by De Gruyter in cooperation with the University of Luxembourg Centre for Contemporary and Digital History. This is an Open Access article distributed under the terms of the [Creative Commons Attribution License CC-BY](https://creativecommons.org/licenses/by/4.0/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "copyright"
    ]
   },
   "source": [
    "[![cc-by-nc-nd](https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-nd/4.0/) \n",
    "©<AUTHOR or ORGANIZATION / FUNDER>. Published by De Gruyter in cooperation with the University of Luxembourg Centre for Contemporary and Digital History. This is an Open Access article distributed under the terms of the [Creative Commons Attribution License CC-BY-NC-ND](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "cover"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAACWBAMAAABkyf1EAAAAG1BMVEXMzMyWlpacnJyqqqrFxcWxsbGjo6O3t7e+vr6He3KoAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEcElEQVR4nO2aTW/bRhCGh18ij1zKknMkbbf2UXITIEeyMhIfRaF1exQLA/JRclslRykO+rs7s7s0VwytNmhJtsA8gHZEcox9PTs7uysQgGEYhmEYhmEYhmEYhmEYhmEYhmEYhmEYhmEYhmEYhmGYr2OWRK/ReIKI8Zt7Hb19wTcQ0uTkGh13bQupcw7gPOvdo12/5CzNtNR7xLUtNtT3CGBQ6g3InjY720pvofUec22LJPr8PhEp2OMPyI40PdwWUdronCu9yQpdPx53bQlfLKnfOVhlnDYRBXve4Ov+IZTeMgdedm0NR+xoXJeQvdJ3CvziykSukwil16W/Oe7aGjIjqc/9ib4jQlJy0uArtN4A0+cvXFvDkmUJ47sJ1Y1ATLDNVXZkNPIepQzxy1ki9fqiwbUj/I+64zxWNzyZnPuhvohJ9K70VvXBixpcu2SAHU+Xd9EKdEJDNpYP3AQr3bQSpPQ6Y6/4dl1z7ZDbArsszjA7L0g7ibB0CDcidUWVoErvIMKZh2Xs0LUzcLW6V5NfiUgNEbaYmAVL6bXl0nJRc+1S72ua/D/cTjGPlQj7eUqd7A096rYlRjdPYlhz7VIvxpVG3cemDKF+WAwLY/6XelOZKTXXzsC4xvDjjtSN6kHLhLke6PrwM8h1raf40qjrGO7H9aTEbduucjS04ZrYU/4iuS5Z2Hdt0rvCLFdmLEXcU30AGddST62o+sLcf5l6k7CP+ru4pLYqX/VFyxbm/utQbx/r22ZEbTb2f5I2kns1Y1OQR8ZyofX+TjJxj1Rz7QQVnf1QzR26Oth0ueJVYcRP6ZUPac/Rx/5M6ixO1dhSrT3Y1DpiYmx3tF4ZUdpz9LD/dSg9PXES0LB71BwcGjKROuV28lnvnv7HHJsezheBGH5+X2CfSfRbMKW+5aGs3JFjMrjGibJc0S7TJzqjHrh2hDybj9XRXNZa89Aro55XBdbW5wti2c/5WJ7jJ1RolVUn/HWpb0I58Tziup6Rx7Dm2hnbRP1GM9PW/NFmQ4PtVRVN63Wvxfmu5sowDMMwDMMwDMMwDMMwDMMwDMMwzL+CpT//F/6beoV8zb2Jmt4Qryx6lTUCsENQ75HOkhXAO3EPVgyQtKtUy3C/e+FJg17Zjnew1Xrdb9InbG4WqfUAftG+WhLwPVyfg536+MU7m4C1CMk4ZznpXZzDYI1PDL2nS1hpvc5cNd7E2sJg05Fe7/7d3Fln8Cvc3bwB616auxsKl4WPghjemHrDqyDWeu1UNW5s2btPnSQ75oOdunEwWazfwgVG0kqluYCM9OIjWOGnfA2b9G4Ha63XKpvQ8perTvTifJNhi6+WMWmi7smEZf6G8MmhlyGq+NqP8GV84TLuJr7UIQVx+bDEoEpRZIz42gs40OuN4Mv8hXzelV7KX1isH+ewTWckikyVv+CfHuqVF7I16gN0VKypX6wPsE+zFPzkinolU9UH8OMGvSpnZqKsv13p/RsMun6X5x/y2LeAr8O66lsBwzBMP/wJfyGq8pgBk6IAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\"./media/placeholder.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "disclaimer"
    ]
   },
   "source": [
    " (optional) This article was orginally published (...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "keywords"
    ]
   },
   "source": [
    "FirstKeyword, SecondKeyword, AlwaysSeparatedByAComma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "abstract"
    ]
   },
   "source": [
    "This article examines how digital historians are using large language models (LLMs) in their research and teaching, along with the critical and ethical debates surrounding their use. The article first assesses the historical capacities of LLMs as measured by machine learning benchmarks, and how such assessments can help historians understand the capacities and limits of these technologies. The utility of LLMs as digital tools are then demonstrated through a series of case studies using GPT-4 and other generative AI models. LLMs are tasked with a variety of tasks for streamlining data preparation, such as oral history transcription, correcting optical character recognition (OCR) errors, and metadata extraction. These case studies also demonstrate how frameworks for using LLMs, such as prompt engineering and retrieval augmented generation (RAG), are used to ground LLM outputs for consistency and greater accuracy. Acknowledging the significant ethical challenges posed by LLMs, the article emphasizes the need for critical engagement and the development of responsible frameworks for implementing these technologies in historical scholarship. By combining disciplinary expertise with innovative computational approaches, historians are discovering new ways to navigate the \"unheard-of historical abundance\" of the digital age, contributing to approaches to generative AI that enriches, rather than distorts, our understanding of the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This is the first paragrah of running text with a citation example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "5w5sr": [
       {
        "id": "27937/XQYUJV5F",
        "source": "zotero"
       }
      ],
      "fgell": [
       {
        "id": "27937/CJYNFHVI",
        "source": "zotero"
       }
      ],
      "uo7pa": [
       {
        "id": "27937/L2ILKERU",
        "source": "zotero"
       }
      ]
     }
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "In 2003, Roy Rosenzweig predicted that digital historians would need to develop new techniques \"to research, write, and teach in a world of unheard-of historical abundance.\" (<cite id=\"fgell\"><a href=\"#zotero%7C27937%2FCJYNFHVI\">Rosenzweig, “Scarcity or Abundance?”</a></cite>) Over the past two decades historians have risen to this challenge, embracing digital mapping, network analysis, distant reading of large text collections, and machine learning as part of their growing methodological toolkit. (<cite id=\"uo7pa\"><a href=\"#zotero%7C27937%2FL2ILKERU\">Graham, Milligan, and Weingart, <i>Exploring Big Historical Data</i>.</a></cite>) Generative artificial intelligence (AI) has emerged as another potential tool that historians are using to explore the past, particularly large language models (LLMs), the most prominent form of this technology. These models possess striking capacities to generate, interpret, and manipulate data across a range of modalities. The rapidly-expanding scope of these capabilities and their limits remain intensely debated, as do their broader social, economic, cultural, and environmental impacts. Yet while still an emerging technology, historians are already demonstrating generative AI's potential as a versatile digital tool. Historians are also contributing to the critical discourse surrounding this new domain, raising key questions about how these models achieve their capabilities, their propensity to reinforce existing inequalities, and their potential to distort our understanding of the past. (<cite id=\"5w5sr\"><a href=\"#zotero%7C27937%2FXQYUJV5F\">Meadows and Sternfeld, “Artificial Intelligence and the Practice of History.”</a></cite>)\n",
    "\n",
    "This article contributes to this discourse by demonstrating how digital historians are using generative AI to explore the past, as well as the disciplinary opportunities historians can offer to these broader debates. We begin by assessing the metrics commonly used to measure the historical knowledge of LLMs, and examine how such metrics can give us insights into the capacities and limits this technology. We then examine how generative AI can be used in tasks as varied as preparing datasets, exploring text collections, and offering novel (and controversial) methods of representing the past. We conclude with a call to historians to continue to contribute to ongoing research and debates concerning the ethical use of generative AI. Given the rapid pace of innovation in this field, it is crucial that the profession addresses the implications of this technology for our research and teaching. Historians will have much to contribute in contextualizing the innovative and disruptive potential of these breakthroughs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Do AIs Know About History? Assessing LLMs for Historical Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "4e7tr": [
       {
        "id": "27937/9T2I7QLM",
        "source": "zotero"
       }
      ],
      "e95sf": [
       {
        "id": "27937/KNEK45E4",
        "source": "zotero"
       }
      ],
      "ucor9": [
       {
        "id": "27937/56EE9N63",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "As historians explore the possibilities of generative AI, it is important to understand how these technologies are created and assessed. With this knowledge we can better evaluate their potential utility and their limits.\n",
    "\n",
    "\n",
    "<cite id=\"e95sf\"><a href=\"#zotero%7C27937%2FKNEK45E4\">Brown et al., “Language Models Are Few-Shot Learners.”</a></cite>\n",
    "\n",
    "As historians explore the possibilities of generative AI, it is important to understand how these technologies are created and assessed. With this knowledge we can better evaluate their potential utility and their limits.\n",
    "\n",
    "At the most fundamental level, generative AI models like LLMs are statistical representations of the datasets on which they are trained. Machine learning techniques like deep learning and recent innovations like the Transformer network architecture (<cite id=\"4e7tr\"><a href=\"#zotero%7C27937%2F9T2I7QLM\">Vaswani et al., “Attention Is All You Need.”</a></cite>) have enabled the creation of models capable of mimicking the data on which they are trained with a high degree of fidelity. But researchers have also discovered that with sufficient time and the application of (often immense) computational power, these models exhibit a range of “emergent” capabilities. (<cite id=\"ucor9\"><a href=\"#zotero%7C27937%2F56EE9N63\">Wei et al., “Emergent Abilities of Large Language Models.”</a></cite>) For example, LLMs can summarize texts, perform language translation, write working computer code, and compose informative responses on a wide array of subjects - all without specific training on how to perform such tasks. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "1ggr3": [
       {
        "id": "27937/H9BUWE28",
        "source": "zotero"
       }
      ],
      "47zjl": [
       {
        "id": "27937/56EE9N63",
        "source": "zotero"
       }
      ],
      "drdmm": [
       {
        "id": "27937/KNEK45E4",
        "source": "zotero"
       }
      ],
      "jxtri": [
       {
        "id": "27937/9T2I7QLM",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "<cite id=\"1ggr3\"><a href=\"#zotero%7C27937%2FH9BUWE28\">Kaplan et al., “Scaling Laws for Neural Language Models.”</a></cite>\n",
    "\n",
    "<cite id=\"jxtri\"><a href=\"#zotero%7C27937%2F9T2I7QLM\">Vaswani et al., “Attention Is All You Need.”</a></cite>\n",
    "\n",
    "<cite id=\"47zjl\"><a href=\"#zotero%7C27937%2F56EE9N63\">Wei et al., “Emergent Abilities of Large Language Models.”</a></cite>\n",
    "\n",
    "<cite id=\"drdmm\"><a href=\"#zotero%7C27937%2FKNEK45E4\">Brown et al., “Language Models Are Few-Shot Learners.”</a></cite>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "76vdj": [
       {
        "id": "27937/56EE9N63",
        "source": "zotero"
       }
      ],
      "gay3h": [
       {
        "id": "27937/H9BUWE28",
        "source": "zotero"
       }
      ],
      "m7x9c": [
       {
        "id": "27937/9T2I7QLM",
        "source": "zotero"
       }
      ],
      "q322b": [
       {
        "id": "27937/KNEK45E4",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "<cite id=\"m7x9c\"><a href=\"#zotero%7C27937%2F9T2I7QLM\">Vaswani et al., “Attention Is All You Need.”</a></cite>\n",
    "\n",
    "<cite id=\"76vdj\"><a href=\"#zotero%7C27937%2F56EE9N63\">Wei et al., “Emergent Abilities of Large Language Models.”</a></cite>\n",
    "\n",
    "<cite id=\"q322b\"><a href=\"#zotero%7C27937%2FKNEK45E4\">Brown et al., “Language Models Are Few-Shot Learners.”</a></cite>\n",
    "\n",
    "<cite id=\"gay3h\"><a href=\"#zotero%7C27937%2FH9BUWE28\">Kaplan et al., “Scaling Laws for Neural Language Models.”</a></cite>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "5rfo9": [
       {
        "id": "27937/RRLN9TF5",
        "source": "zotero"
       }
      ],
      "l99eo": [
       {
        "id": "27937/QPK6D3M9",
        "source": "zotero"
       }
      ],
      "nppps": [
       {
        "id": "27937/U534FF7L",
        "source": "zotero"
       }
      ],
      "q7whc": [
       {
        "id": "27937/ZICATXAV",
        "source": "zotero"
       }
      ],
      "r8lyr": [
       {
        "id": "27937/UYVGUT4C",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "While the Generative Pre-trained Transformer (GPT) series from OpenAI is the best known of these foundational models, there has been a rapid proliferation of commercial and open-source alternatives. Notable recent LLMs include Google’s Gemini, Anthropic’s Claude, and open-source models offered by Meta and Mistral.\n",
    "\n",
    "Foundational models are also emerging in other domains, such as image, video, and audio synthesis. Architectures like CLIP (<cite id=\"r8lyr\"><a href=\"#zotero%7C27937%2FUYVGUT4C\">Radford et al., “Learning Transferable Visual Models From Natural Language Supervision.”</a></cite>) enable the creation of synthetic imagery in models like OpenAI’s DALL-E, Midjourney, and the open-source community behind Stable Diffusion. Similar approaches for generating video, speech, and music have been developed by firms like Runway-XL, ElevenLabs, and Suno, along with open-source alternatives hosted on sites likes HuggingFace. Most notably, new forms of LLM-training have enabled the a combination of these capacities in multi-modal models capable of working across multiple domains, such as OpenAI’s GPT-4 series. (<cite id=\"nppps\"><a href=\"#zotero%7C27937%2FU534FF7L\">OpenAI, “GPT-4 Technical Report.”</a></cite>)\n",
    "\n",
    "An accessible way to stay abreast of recent innovations in this field is by following the leaderboards used to measure performance on standard LLM benchmarks. LLMArena’s Chatbot Arena (<cite id=\"q7whc\"><a href=\"#zotero%7C27937%2FZICATXAV\">“Chatbot Arena (Formerly LMSYS).”</a></cite>) offers an overview of leading contemporary models, while HuggingFace’s Open LLM Leaderboard (<cite id=\"l99eo\"><a href=\"#zotero%7C27937%2FQPK6D3M9\">“Open LLM Leaderboard 2 - a Hugging Face Space by Open-Llm-Leaderboard.”</a></cite>) and the Open Multilingual LLM Evaluation Leaderboard () offer specialized metrics for particular domains and use-cases. (<cite id=\"5rfo9\"><a href=\"#zotero%7C27937%2FRRLN9TF5\">“Open Multilingual Llm Leaderboard - a Hugging Face Space by Uonlp.”</a></cite>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "7zssq": [
       {
        "id": "27937/BXZEP65G",
        "source": "zotero"
       }
      ],
      "pl7am": [
       {
        "id": "27937/MVDFMR8K",
        "source": "zotero"
       }
      ],
      "sj7gk": [
       {
        "id": "27937/EZNK3CE3",
        "source": "zotero"
       }
      ],
      "xw5wn": [
       {
        "id": "27937/FMW5DCWM",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "While such claims have sparked both excitement and alarm, any assessment of LLMs must first be tempered with humility. LLMs are often described as possessing “knowledge” and “understanding,” yet direct engagement with these models can quickly reveal both their remarkable breadth and their narrow limits. Incisive critics of this technology characterize LLMs as “stochastic parrots” that excel at uncanny mimicry of human intelligence. <cite id=\"pl7am\"><a href=\"#zotero%7C27937%2FMVDFMR8K\">Bender et al., “On the Dangers of Stochastic Parrots | Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency.”</a></cite> A form of this mimicry has proven convincing in the past. The first attribution of true artificial intelligence to a computer program occurred in 1966 with a scripted chatbot named ELIZA, developed by AI pioneer Joseph Weizenbaum. <cite id=\"sj7gk\"><a href=\"#zotero%7C27937%2FEZNK3CE3\">McCorduck, <i>Machines Who Think a Personal Inquiry into the History and Prospects of Artificial Intelligence</i>.</a></cite> A recent replication of this phenomenon occurred in June 2022 when a Google AI engineer declared the LLM he was training had become sentient. <cite id=\"7zssq\"><a href=\"#zotero%7C27937%2FBXZEP65G\">“What Is LaMDA and What Does It Want? | by Blake Lemoine | Medium.”</a></cite> Such attributions will likely increase as newer LLMs demonstrate increasing proficiency in seemingly distinct human qualities, like humor. <cite id=\"xw5wn\"><a href=\"#zotero%7C27937%2FFMW5DCWM\">Chowdhery et al., “PaLM.”</a></cite> The means by which LLMs process, interpret, and generate information is a highly technical field requiring specialization in natural language processing, statistics, computational linguistics, and machine learning. While most historians may lack the technical knowledge to effectively evaluate the merits of these debates, when it comes to our own domain we are well equipped to offer informed insights.\n",
    "\n",
    "Indeed, the standard measurement for a LLM’s historical knowledge was inadvertently created by historians. One widely-used measure for LLM performance is the Massive Multitask Language Understanding (MMLU) benchmark, developed in 2021 by a researchers led by Dan Hendryks. This benchmark contains nearly 16,000 questions from 57 academic disciplines ranging in difficulty from an elementary educational level to postgraduate curricula in professional domains like law and medicine. History is measured in this benchmark through questions taken from the Advanced Placement (A.P.) curricula for U.S., European, and World history. Hundreds of thousands of secondary students across the globe annually enroll in these curricula, which are designed to replicate the rigors of an introductory university-level history course. The educators who developed and refined these programs likely never imagined their work would serve as a technical benchmark, and the appropriateness of such a standard can be debated. Yet this benchmark, however imperfect, offers historians an accessible means to evaluate this highly technical domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this benchmark LLMs are given an excerpt from a historical source followed a multiple-choice question, and are then instructed to identify the correct answer. Below is an example question drawn from the U.S. History curriculum:\n",
    "\n",
    "**U.S. History Benchmark, Question 5:**\n",
    "\n",
    "This question refers to the following information.\n",
    "\n",
    "“I was once a tool of oppression\n",
    "And as green as a sucker could be\n",
    "And monopolies banded together\n",
    "To beat a poor hayseed like me.”\n",
    "\n",
    "“The railroads and old party bosses\n",
    "Together did sweetly agree;\n",
    "And they thought there would be little trouble\n",
    "In working a hayseed like me. . . .”\n",
    "\n",
    "“The Hayseed”\n",
    "\n",
    "The song, and the movement that it was connected to, highlight which of the following developments in the broader society in the late 1800s?\n",
    "\n",
    "A: Corruption in government, especially as it related to big business, energized the public to demand increased popular control and reform of local, state, and national governments.\n",
    "B: A large-scale movement of struggling African American and white farmers, as well as urban factory workers, was able to exert a great deal of leverage over federal legislation.\n",
    "C: The two-party system of the era broke down and led to the emergence of an additional major party that was able to win control of Congress within ten years of its founding.\n",
    "D: Continued skirmishes on the frontier in the 1890s with American Indians created a sense of fear and bitterness among western farmers.\n",
    "\n",
    "**Correct Answer: A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "wfmit": [
       {
        "id": "27937/ZS9JDNGD",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "The MMLU benchmarks were first tested in 2021 against the then-leading LLM, OpenAI’s GPT-3. Twenty-five percent accuracy represented random chance; ninety percent performance reflected expert-level accuracy. GPT-3 initially achieved over fifty percent accuracy on all three A.P. curricula, and its performance in these subfields numbered among the top third of all the academic disciplines in the benchmarks. However, in no field did GPT-3 achieve expert-level accuracy, and the model demonstrated particularly poor performance in the fields of “Moral Questions” and “Professional Law.” As the authors note, this “weakness is particularly concerning because it will be important for future models to have a strong understanding of what is legal and what is ethical.” (<cite id=\"wfmit\"><a href=\"#zotero%7C27937%2FZS9JDNGD\">Hendrycks et al., “Measuring Massive Multitask Language Understanding.”</a></cite>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "tbd8o": [
       {
        "id": "27937/A834FRJL",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "The specific accuracy rates for GPT-3 for the initial Hendryks study: US History, 52.9%; European History, 53.9%; and World History, 56.1%. Full data for questions for history and other disciplines can be found at: (<cite id=\"tbd8o\"><a href=\"#zotero%7C27937%2FA834FRJL\">Hendrycks, <i>Measuring Massive Multitask Language Understanding</i>.</a></cite>) Many thanks to Dan Hendrycks for sharing the discipline-specific accuracy rates for these fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, rapid advances in model development have occurred since 2021. Subsequent tests on newer models “scaled” on ever greater amounts of data and computation demonstrate substantial gains in performance on these historical benchmarks. Below are results from a replication study conducted in September 2024 across a series of leading LLMs, along with the initial Hendryks test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block for Displaying MMMU Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "s177q": [
       {
        "id": "27937/5AL5LZ2K",
        "source": "zotero"
       }
      ],
      "s4luc": [
       {
        "id": "27937/GSIXPJ7P",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Data from this replication study can be accessed via the HELM Leaderboard for the MMLU Benchmark, hosted by the Center for Research on Foundation Models at Stanford University. (<cite id=\"s4luc\"><a href=\"#zotero%7C27937%2FGSIXPJ7P\">Mai and Liang, “Massive Multitask Language Understanding (MMLU) on HELM.”</a></cite>) You can directly experiment with LLM performance on these benchmarks via a digital history project accompanying this article, “What Do AIs Know About History?” (<cite id=\"s177q\"><a href=\"#zotero%7C27937%2F5AL5LZ2K\">“What Do AIs Know About History? A Digital History Experiment by Daniel Hutchinson · Streamlit.”</a></cite>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "3unok": [
       {
        "id": "27937/YVTAGDKZ",
        "source": "zotero"
       }
      ],
      "55r4n": [
       {
        "id": "27937/KNEK45E4",
        "source": "zotero"
       }
      ],
      "5a9qa": [
       {
        "id": "27937/BD8996H7",
        "source": "zotero"
       }
      ],
      "6cssb": [
       {
        "id": "27937/9GQG6VFM",
        "source": "zotero"
       }
      ],
      "6ph9l": [
       {
        "id": "27937/5YDNQS4V",
        "source": "zotero"
       }
      ],
      "8fjtz": [
       {
        "id": "27937/VEDFUUBA",
        "source": "zotero"
       }
      ],
      "97pas": [
       {
        "id": "27937/X4D92B7V",
        "source": "zotero"
       }
      ],
      "ahtmn": [
       {
        "id": "27937/BVBZMR66",
        "source": "zotero"
       }
      ],
      "c6t3w": [
       {
        "id": "27937/TPGPSRAI",
        "source": "zotero"
       }
      ],
      "fpott": [
       {
        "id": "27937/IEQ8GAVU",
        "source": "zotero"
       }
      ],
      "gzk2l": [
       {
        "id": "27937/R5P23ZWU",
        "source": "zotero"
       }
      ],
      "j1kj5": [
       {
        "id": "27937/KNEK45E4",
        "source": "zotero"
       }
      ],
      "jm1mt": [
       {
        "id": "27937/5GTQD5W9",
        "source": "zotero"
       }
      ],
      "kba8r": [
       {
        "id": "27937/U534FF7L",
        "source": "zotero"
       }
      ],
      "r1ql3": [
       {
        "id": "27937/TGPDB8WX",
        "source": "zotero"
       }
      ],
      "vuott": [
       {
        "id": "27937/MVDFMR8K",
        "source": "zotero"
       }
      ],
      "xndfm": [
       {
        "id": "27937/NYNDVYMM",
        "source": "zotero"
       }
      ],
      "yh6j9": [
       {
        "id": "27937/S3ADX5DD",
        "source": "zotero"
       }
      ],
      "zsn16": [
       {
        "id": "27937/MHRIEHH8",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "Rapid improvement on this benchmark have been made in just a few years, with a variety of commercial and open-source LLMs now demonstrating expert-level accuracy on all three of the subject exams. These findings mirror the striking performance of models like GPT-4 in other knowledge domains such as medical school curricula (<cite id=\"8fjtz\"><a href=\"#zotero%7C27937%2FVEDFUUBA\">Nori et al., “Capabilities of GPT-4 on Medical Challenge Problems.”</a></cite>), American bar exams, (<cite id=\"ahtmn\"><a href=\"#zotero%7C27937%2FBVBZMR66\">Katz, “GPT Takes the Bar Exam.”</a></cite>), and a host of other standardized assessments. (<cite id=\"kba8r\"><a href=\"#zotero%7C27937%2FU534FF7L\">OpenAI, “GPT-4 Technical Report.”</a></cite>)\n",
    "\n",
    "Yet, why do some LLMs perform better in some knowledge domains than others? How can a model get one question right, while other questions generate errors? There is a temptation to parse the model’s performance in ways relatable to our human perspective. The human test taker might approach the question by assessing what types of historical thinking each question requires, what sort of knowledge is offered by the options, and how the historical source relates to the question. But, of course, LLMs aren’t human - and unlike the human test taker, these models have already seen the questions in advance. In 2022 alone, over 800,000 students took A.P. History exams. (<cite id=\"5a9qa\"><a href=\"#zotero%7C27937%2FBD8996H7\">“Program Summary Report.”</a></cite>) Significant online resources have emerged to serve the sizable population of students and instructors participating in this international curriculum. Hundreds of exam questions have migrated online via the collective efforts of the test prep publishing industry, various study apps, and uploaded example tests.\n",
    "\n",
    "Thus the capabilities of LLMs on these benchmarks directly relates to the vast dataset used to train them: the Internet itself. The data collection built for training GPT-3 encompassed the majority of English-language Wikipedia, Reddit’s thousands of discussion forums, extensive corpora of digitized books, and the billions of web pages contained in the Common Crawl repository. (<cite id=\"55r4n\"><a href=\"#zotero%7C27937%2FKNEK45E4\">Brown et al., “Language Models Are Few-Shot Learners.”</a></cite>) The training sets used for subsequent LLMs remains largely unknown, as AI firms keep their data a closely guarded and proprietary asset; indeed, the future of LLMs may depend on pending litigation concerning copyright infringement in the use of this data. Yet given the scale of such datasets, many of the A.P. History questions used in these benchmarks have likely ended up in LLM training data. If those who critique LLMs as “stochastic parrots” are correct, these gains in performance come from improvements in models memorizing this data, and not through any analytical process. (<cite id=\"vuott\"><a href=\"#zotero%7C27937%2FMVDFMR8K\">Bender et al., “On the Dangers of Stochastic Parrots | Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency.”</a></cite>) When LLMs encounter questions outside of their training, their accuracy is likely to suffer.\n",
    "\n",
    "Yet such inaccuracies can be difficult to detect. LLMs tend to confidently assert error as fact, a phenomenon described by AI researchers as “hallucinations.” Such hallucinations represent a major challenge in LLM research and for many practical applications of this technology, particularly given the remarkable effectiveness of these models in generating convincing and otherwise accurate prose. (<cite id=\"6cssb\"><a href=\"#zotero%7C27937%2F9GQG6VFM\">Ji et al., “Survey of Hallucination in Natural Language Generation.”</a></cite>)  Initial testing by OpenAI on the GPT series demonstrated that human readers often struggle to identify text generated by LLMs. (<cite id=\"j1kj5\"><a href=\"#zotero%7C27937%2FKNEK45E4\">Brown et al., “Language Models Are Few-Shot Learners.”</a></cite>) Rectifying such hallucinations is a significant area of LLM research. However, some scholars, like computational linguist Emily Bender, argue that such behaviors are inherent flaws in LLMs. (<cite id=\"c6t3w\"><a href=\"#zotero%7C27937%2FTPGPSRAI\">Bender, “On NYT Magazine on AI.”</a></cite>)\n",
    "\n",
    "Additional risks confront historians using these technologies. While AI firms seek to remove potentially offensive texts from their training sets, the sheer scale of this data make selective curation very challenging. LLMs thus generate responses reflecting both the best and the worst of our online world. This reality has troubled previous AI implementations. Well-intentioned researchers have created chatbots that spew hateful invective, human resources applications that refuse to hire female applicants, and algorithms based on criminal justice sentencing guidelines that starkly reinforce racial disparities already prevalent in the carceral system. (<cite id=\"6ph9l\"><a href=\"#zotero%7C27937%2F5YDNQS4V\">Barton, “Algorithmic Bias Detection and Mitigation.”</a></cite>) Early models in the GPT series have been known to unexpectedly generate responses in innocuous contexts containing violent imagery, sexually explicit language, and racial, ethnic, and religious slurs. (<cite id=\"xndfm\"><a href=\"#zotero%7C27937%2FNYNDVYMM\">“OpenAI’s GPT-3 Speaks! (Kindly Disregard Toxic Language) - IEEE Spectrum.”</a></cite>) These findings further confirm the prescient warnings offered by scholars such as Safiya Umoja Noble (<cite id=\"fpott\"><a href=\"#zotero%7C27937%2FIEQ8GAVU\">Noble, <i>Algorithms of Oppression</i>.</a></cite>), Timnit Gebru (<cite id=\"yh6j9\"><a href=\"#zotero%7C27937%2FS3ADX5DD\">Gebru, “Race and Gender.”</a></cite>), Ruha Benjamin (<cite id=\"97pas\"><a href=\"#zotero%7C27937%2FX4D92B7V\">Benjamin, <i>Race After Technology</i>.</a></cite>), Kate Crawford <cite id=\"3unok\"><a href=\"#zotero%7C27937%2FYVTAGDKZ\">Crawford, <i>Atlas of AI</i>.</a></cite>, and Trevor Paglen (<cite id=\"jm1mt\"><a href=\"#zotero%7C27937%2F5GTQD5W9\">“Excavating AI.”</a></cite>) on digital practices that reinforce analog inequalities. Some AI researchers consider such behaviors as lamentable but solvable problems through further technical advances, particularly with the use of methods like Reinforcement Learning from Human Feedback (RLHF). (<cite id=\"r1ql3\"><a href=\"#zotero%7C27937%2FTGPDB8WX\">Christiano et al., “Deep Reinforcement Learning from Human Preferences.”</a></cite>) Reducing the impact of such biases is a significant research area, particularly through the creation of smaller, more carefully curated datasets for AI training. However, many historians will likely share the skepticism of some researchers concerning such mitigations. (<cite id=\"zsn16\"><a href=\"#zotero%7C27937%2FMHRIEHH8\">Gehman et al., “RealToxicityPrompts.”</a></cite>) Bias emerges from more than just explicit language or imagery but from the very structures of societies. Can any historical source be separated from its context as a neutral artifact, free of its creator’s perspective and the influences of its time? What about the untold millions of sources that make up the scale of an LLM’s training set?\n",
    "\n",
    "To be sure, LLMs are imperfect digital tools, and given these flaws historians must exercise caution when employing this technology. Yet scholars are finding that within the confines of these imperfections there is real potential to advance historical research. While a LLM’s facility with multiple-choice questions might be the product of memorization, such knowledge has long been a springboard for more advanced forms of inquiry. And A.P. study guides are not the only historical texts LLMs are trained on. Primary source collections, academic monographs, open-source scholarly journals - these too inform an LLM’s training. The influence of these sources can be found when LLMs are posed more complex questions in a structured prompt. Let’s return to the earlier A.P. question above featuring the Populist-era campaign song “The Hayseed.” In the code blocks below, GPT-4 is given the lyrics and publication history of the song. (<cite id=\"gzk2l\"><a href=\"#zotero%7C27937%2FR5P23ZWU\">“The Farmers’ Alliance. (Lincoln, Nebraska) 1889-1892, October 04, 1890, Image 1 « Nebraska Newspapers.”</a></cite>) GPT-4 is then prompted to identify the larger historical context of the source, the song’s intended purpose and audience, and how the source might be interpreted via different historiographical approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for loading hayseed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for loading prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for API call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "rxaxc": [
       {
        "id": "27937/G5ESJ8NI",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "While one can debate aspects of GPT-4’s interpretations, it nonetheless accurately captures much of the context and intent of the source. With the right design, LLMs could be automated to annotate an entire corpus of archival sources in a similar manner, becoming a tool of the digital historian overwhelmed by an abundance of historical data, as envisioned by Roy Rozenweig twenty years ago. Yet LLM outputs and hallucinations are already contributing to this deluge of data. Both benign and malicious use of these technologies are impacting our understanding of the past and ability to comprehend the present. Historians should contribute to the broader dialogue about the implications and informed use of these technologies, especially as they become increasingly embedded in our digital lives. Further experimentation is also needed to more fully assess LLM’s capabilities for historical interpretation, as well as the creation of new benchmarks to test different approaches to historical analysis. But progress moves quickly in the field of generative AI, and there is intense competition to build new models that advance the existing capabilities of LLMs while shedding their shortcomings. Yet progress remains uneven. Of significant concern are LLM’s performance on benchmarks on ethics and morality, which continue to demonstrate troubling areas of weakness. (<cite id=\"rxaxc\"><a href=\"#zotero%7C27937%2FG5ESJ8NI\">Hoffmann et al., “Training Compute-Optimal Large Language Models.”</a></cite>)\n",
    "\n",
    "While imperfect tools, their flaws do not mean that LLMs have no place in the historian’s toolkit. In fact, by acknowledging and confronting these shortcomings, historians can better contribute our disciplinary perspectives on the debates concerning this technology, particularly in leveraging the strengths of these models to empower and broaden accessibility to historical sources. The case studies below demonstrate how historians are using LLMs as a versatile tools for both researching and communicating the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting LLMs for Digital History: Case Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "c1hh3": [
       {
        "id": "27937/XEUKQDPE",
        "source": "zotero"
       }
      ],
      "zf8ru": [
       {
        "id": "27937/VXGSAGTI",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "A promising approach for LLMs and other foundational AI models lies in their capacity to transform data preparation and cleanup – a process that often constitutes an estimated 80% of the labor involved in preparing data for analysis. (<cite id=\"zf8ru\"><a href=\"#zotero%7C27937%2FVXGSAGTI\">Dasu and Johnson, <i>Exploratory Data Mining and Data Cleaning</i>.</a></cite>) Digitized historical materials frequently require transcriptions, error correction, and the creation of extensive metadata. These essential but time-consuming tasks can become bottlenecks that impede research progress. However, through use of simple prompting techniques historians can leverage the power of LLMs to streamline and accelerate the creation of “tidy datasets” possessing standardized and ordered structures essential for analysis and replication. (<cite id=\"c1hh3\"><a href=\"#zotero%7C27937%2FXEUKQDPE\">Wickham, “Tidy Data.”</a></cite>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Oral History Transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "d9rvh": [
       {
        "id": "27937/7VHKCH3M",
        "source": "zotero"
       }
      ],
      "etf8p": [
       {
        "id": "27937/YWJAQ4V8",
        "source": "zotero"
       }
      ],
      "p2yor": [
       {
        "id": "27937/IJWETJM7",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "Oral history provides a particularly useful case study for demonstrating the potential utility of generative AI. Transcribing audio recordings is a central labor in this methodology, a task typically requiring significant time and labor. As one oral history guide notes, transcribing a single hour typically requires six to eight hours of manual processing and review. (<cite id=\"etf8p\"><a href=\"#zotero%7C27937%2FYWJAQ4V8\">Ritchie, <i>Doing Oral History</i>.</a></cite>) However, advances in specialized generative AI models permits significant streamlining of this task.\n",
    "\n",
    "Notable among these models is Whisper, an open-source audio transcription and translation model developed by OpenAI that belongs to the same Transformer family as the GPT series. (<cite id=\"d9rvh\"><a href=\"#zotero%7C27937%2F7VHKCH3M\">Radford et al., “Robust Speech Recognition via Large-Scale Weak Supervision.”</a></cite>) Trained on over 180,000 hours of audio recordings, this model demonstrates performance comparable (and in some cases exceeding) the accuracy rates of human transcriptions in over 57 languages. In this test we’ll examine Whisper’s performance on the first two minutes of a transcribed oral history of historian John Hope Franklin by the Southern Oral History Program. (<cite id=\"p2yor\"><a href=\"#zotero%7C27937%2FIJWETJM7\">“John Hope Franklin and John Egerton, Conducted by Oral History Interview with John Hope Franklin, July 27, 1990. Interview A-0339. Southern Oral History Program Collection (#4007).”</a></cite>) Recorded on audiotape in 1990, this segment features multiple voices, crosstalk, filler words, and background noise - typical features for many oral history recordings, but features that nonetheless complicate efforts to create accurate transcripts. In the code below, we will use Whisper to transcribe the audio segment and compare it against the official transcript. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "9b61q": [
       {
        "id": "27937/GJ2EYJWT",
        "source": "zotero"
       }
      ],
      "kav0z": [
       {
        "id": "27937/I2BKP7MN",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "The Whisper series is offered as a series of open-source voice recognition and voice translation models across several tiers of computing power and freely available on sites like HuggingFace. (<cite id=\"9b61q\"><a href=\"#zotero%7C27937%2FGJ2EYJWT\">“Whisper - a Hugging Face Space by Openai.”</a></cite>) However, for simplicity this demonstration code uses OpenAI’s API for the Whisper-2-large model. As of September 2024, OpenAI charged $0.36 per hour of recorded time for transcriptions using the API.\n",
    "\n",
    "For a detailed and informative tutorial on using and analyzing Whisper, see: (<cite id=\"kav0z\"><a href=\"#zotero%7C27937%2FI2BKP7MN\">Schultz, “[Tutorial] Using Whisper to Transcribe Oral Interviews – CSS @ IPP.”</a></cite>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block - running Whisper on audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below generates a audio player to listen to the audio segment. Listen and follow along to observe Whisper’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block - displaying audio player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the professional standard, this transcription would take approximately fifteen to twenty minutes to manually transcribe. Whisper achieved this in less than ten seconds.\n",
    "\n",
    "How accurate is the model to a human-produced transcript? Due to the stochastic nature of these models, each time you run this code slightly different variations might occur, particularly in the most challenging segments. The code block below visualizes a sample transcription produced by Whisper that was annotated and compared against the original. Notable omissions and discrepancies are highlighted. Whisper’s accuracy is then calculated via a standard benchmark for audio transcription, the word error rate (WER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block - comparing transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "awd3s": [
       {
        "id": "27937/UHZYQM3W",
        "source": "zotero"
       }
      ],
      "km6om": [
       {
        "id": "27937/KKDPZJYW",
        "source": "zotero"
       }
      ],
      "v20p9": [
       {
        "id": "27937/MYFQUX4C",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "There are some suggestive observations we can take from these results. Closer inspection of the Whisper transcript shows some errors, a significant omission, differences in syntax, and literal transcriptions that an edited transcript would likely leave out. But given the media format and its audio quality, the oral historian has a solid first draft in just a few seconds. While the WER score indicates a need for final human review, that review will take considerably less effort and enable oral historians to shift their focus to interpreting, annotating, and validating their transcriptions. And even the best human transcriptions still contain errors. Take note of the final paragraph in the original transcript, which names Harvard as the destination of E. Franklin Frazier in 1934; but the noted sociologist actually joined the faculty of Howard University. Here Whisper accurately corrects a human error in the transcription.\n",
    "\n",
    "Applications like Whisper are already changing the field of oral history, as well as journalism, court reporting, and language translation. (<cite id=\"awd3s\"><a href=\"#zotero%7C27937%2FUHZYQM3W\">Somers, “Whispers of A.I.’s Modular Future | The New Yorker.”</a></cite>) Scholars are using these techniques to complete multi-lingual transcriptions of aging and vulnerable media (<cite id=\"km6om\"><a href=\"#zotero%7C27937%2FKKDPZJYW\">Lehečka et al., “Transformer-Based Speech Recognition Models for Oral History Archives in English, German, and Czech.”</a></cite>) while also enabling new forms of community-based scholarship and teaching (<cite id=\"v20p9\"><a href=\"#zotero%7C27937%2FMYFQUX4C\">“Artificial Intelligence Aids Cultural Heritage Researchers Documenting and Teaching Oral Histories.”</a></cite>) Generative AI is being used to process and transform other media types as well. Just as Whisper transforms spoken language into text, LLMs can be leveraged to process visual information, such as printed or handwritten text, to aid in source digitization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Error Correction of Optical Character Recognition Scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "0dhwm": [
       {
        "id": "27937/9HF43E58",
        "source": "zotero"
       }
      ],
      "0jirx": [
       {
        "id": "27937/ZJW9AI49",
        "source": "zotero"
       }
      ],
      "b6864": [
       {
        "id": "27937/TIAJYHF6",
        "source": "zotero"
       }
      ],
      "g7pxd": [
       {
        "id": "27937/JV9GGCQA",
        "source": "zotero"
       }
      ],
      "kp7bi": [
       {
        "id": "27937/ZXTQBIJU",
        "source": "zotero"
       }
      ],
      "ltaz6": [
       {
        "id": "27937/58X69RSW",
        "source": "zotero"
       }
      ],
      "op3w5": [
       {
        "id": "27937/KNEK45E4",
        "source": "zotero"
       }
      ],
      "swwon": [
       {
        "id": "27937/5G5LJCLC",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "Another potential use case for AI models in digital history is error correction of optical character recognition (OCR) scans. Machine learning techniques, such as those pioneered by the research team at Transkribus, have greatly enhanced the quality, speed, and cost-effectiveness of OCR for a broad range of historical texts. (<cite id=\"b6864\"><a href=\"#zotero%7C27937%2FTIAJYHF6\">Muehlberger et al., “Transforming Scholarship in the Archives through Handwritten Text Recognition.”</a></cite>) However, even high-fidelity OCR scans often produce errors that impact the accessibility and searchability of text collections. (<cite id=\"0jirx\"><a href=\"#zotero%7C27937%2FZJW9AI49\">Milligan, “Illusionary Order.”</a></cite>) In the examples below, we can observe how a LLM can be prompted to correct these errors.\n",
    "\n",
    "The following image is from a newspaper published in a German prisoner-of-war camp in Mississippi during World War II and later microfilmed by the Library of Congress.\n",
    "\n",
    "After first image\n",
    "\n",
    "<cite id=\"op3w5\"><a href=\"#zotero%7C27937%2FKNEK45E4\">Brown et al., “Language Models Are Few-Shot Learners.”</a></cite>\n",
    "\n",
    "Prompt engineerin hemutical section\n",
    "\n",
    "<cite id=\"swwon\"><a href=\"#zotero%7C27937%2F5G5LJCLC\">Saravia, <i>Prompt Engineering Guide</i>.</a></cite>\n",
    "\n",
    "<cite id=\"0dhwm\"><a href=\"#zotero%7C27937%2F9HF43E58\">“Prompt Engineering Guide.”</a></cite>\n",
    "\n",
    "Final concluding section - \n",
    "\n",
    "<cite id=\"ltaz6\"><a href=\"#zotero%7C27937%2F58X69RSW\">Abdin et al., “Phi-3 Technical Report.”</a></cite>\n",
    "\n",
    "<cite id=\"g7pxd\"><a href=\"#zotero%7C27937%2FJV9GGCQA\">“Post-OCR-Correction.”</a></cite>\n",
    "\n",
    "<cite id=\"kp7bi\"><a href=\"#zotero%7C27937%2FZXTQBIJU\">“PleIAs/Post-OCR-Correction · Datasets at Hugging Face.”</a></cite>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block - displaying first image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "5zf5d": [
       {
        "id": "27937/KNEK45E4",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "Let’s compare a human transcription of this image against outputs generated by Google’s Cloud Vision OCR service and GPT-4. In this code block GPT-4 is given the raw OCR output along with a prompt [link] for correcting OCR errors. This prompt includes examples of the task we wish the model to perform and is tailored to the type of data the model will encounter. This method, called few-shot prompting, is a common “prompt engineering” method for effectively guiding LLM generations. (<cite id=\"5zf5d\"><a href=\"#zotero%7C27937%2FKNEK45E4\">Brown et al., “Language Models Are Few-Shot Learners.”</a></cite>) By again using the word error rate (WER), we can compare the relative accuracy of these different techniques against human performance. Discrepancies between the human-created transcription and the OCR outputs are highlighted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "s9wzk": [
       {
        "id": "27937/5G5LJCLC",
        "source": "zotero"
       }
      ]
     }
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "Effectively utilizing LLMs for historical research extends beyond simply inputting text instructions; it demands an understanding of how to guide these models toward desired outcomes. This process, known as “prompt engineering,” has emerged as a critical skill for leveraging the power of LLMs. By carefully structuring instructions and providing relevant context, historians can shape LLM outputs to address a wide array of research needs.\n",
    "\n",
    "Prompt engineering is an iterative process. Historians will often need to experiment with different prompt structures, phrasings, and examples to achieve the desired level of accuracy and relevance from an LLM. The prompts used in this article represent the fruits of such experimentation, with the hope that that offer insights into effective approaches for using LLMs for common historical research tasks.\n",
    "\n",
    "One prominent prompt engineering technique particularly relevant to historical research is few-shot prompting. This method involves providing the LLM with a small number of examples demonstrating the desired task and output format. A few carefully chosen examples can significantly improve the model’s ability to generalize to new, unseen data, an emergent ability of LLMs called “in context learning.” This technique is especially valuable for tasks where explicit rules are difficult to define, allowing the LLM to learn from demonstration rather than strict programming.\n",
    "\n",
    "Few-shot prompting is the most common of a rapidly growing prompt approaches used with LLMs. Regardless of the technique, effective prompt prompting for historical research does not require extensive technical skill, but certainly benefits from the application of specific domain knowledge and tailored to the task and data at hand. Prompting instead calls for an understanding of the nuances of historical sources, methodologies, and historiographical debates. As LLMs become increasingly integrated into digital historical practice, the ability to craft effective prompts may join skills like text analysis, data visualization, and source criticism as useful components of the digital historian’s toolkit.\n",
    "\n",
    "To learn more about the practices of prompt engineering, a good starting place is [DAIR.AI]()’s Prompt Engineering Guide, which lays out accessible examples for various prompting approaches. (<cite id=\"s9wzk\"><a href=\"#zotero%7C27937%2F5G5LJCLC\">Saravia, <i>Prompt Engineering Guide</i>.</a></cite>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block - OCR task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the image quality is satisfactory and the text is printed using modern typefaces, the OCR still generates errors requiring human correction. Correcting even minor errors necessitates substantial review and intervention, representing significant labor when processing a sizable text corpus. The LLM accelerates that task in this case by correcting OCR errors ahead of human review, particularly when guided by detailed instructions and a few examples tailored to the dataset or OCR task.\n",
    "\n",
    "However, there are some limits to this prompt engineering technique. Accuracy falls for both OCR models and LLMs alike when processing images containing considerable ‘noise’ and distortion, as in the image below. But recent LLMs like GPT-4 have been trained on multi-modal data, allowing them to process images as well as text. In the code below, GPT-4 is fed a prompt, the raw OCR output, as well as the original image to help guide the model in correcting OCR errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block - OCR image 2 display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block - OCR task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "27nt7": [
       {
        "id": "27937/ZXTQBIJU",
        "source": "zotero"
       }
      ],
      "t1nqo": [
       {
        "id": "27937/58X69RSW",
        "source": "zotero"
       }
      ],
      "uhpqt": [
       {
        "id": "27937/JV9GGCQA",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "While GPT-4 provides a less accurate transcription for this image, it did significantly correct and improve the OCR output from this difficult and degraded image. There are other means to achieve even better performance. Specialized LLMs trained specifically for OCR tasks, like Microsoft’s Phi model series, show great promise in advancing the fidelity of such corrections. (<cite id=\"t1nqo\"><a href=\"#zotero%7C27937%2F58X69RSW\">Abdin et al., “Phi-3 Technical Report.”</a></cite>) Similarly, Pleias, a French AI research group, has been applying LLMs at scale for post-OCR correction in larger text datasets such as the Common Corpus, which comprises 500 billion words of multilingual text scraped from the Internet.  Their recent release of a multilingual, billion-word dataset of corrected OCR text includes English, French, German, and Italian texts from cultural heritage repositories such as Gallica and Chronicling America. (<cite id=\"27nt7\"><a href=\"#zotero%7C27937%2FZXTQBIJU\">“PleIAs/Post-OCR-Correction · Datasets at Hugging Face.”</a></cite>) However, while the quality of these corrections has shown significant improvement, Pleias’ work also highlights potential limitations of LLM-based OCR correction. Early tests revealed issues such as language-switching (e.g., parts of English texts mistakenly corrected into French or German) and the risk of hallucinations. (<cite id=\"uhpqt\"><a href=\"#zotero%7C27937%2FJV9GGCQA\">“Post-OCR-Correction.”</a></cite>) Despite these limitations, the potential for LLMs in post-OCR correction is significant. As LLMs continue to evolve, their capacity to perform tasks like OCR correction will likely improve, but human review will remain essential to ensure accuracy and prevent errors.\n",
    "\n",
    "These two case studies demonstrate an LLMs capacity to assist in various forms of data cleanup and preparation. While human review remains essential, LLMs can make that review less time-consuming and labor-intensive. Such approaches can improve the accuracy, lower the costs, and accelerate the pace of data preparation. The same is true for data extraction. In the following example, a LLM will demonstrate how such data can be captured by use of guided prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Structured Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "3y4ir": [
       {
        "id": "27937/HIPL38QS",
        "source": "zotero"
       }
      ],
      "6161c": [
       {
        "id": "27937/68YHDUH6",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "Automated data extraction has increasingly become an important part of digital scholarship. Reseachers have utilized a variety of machine learning and computational approaches for compiling ordered data from historical media. Named entity recognition (NER) is one such example, a method which uses models like spaCy to extract locations, events, individuals, and even concepts from texts into ordered classifications. Such techniques have enabled the creation of rich metadata from archival collections (<cite id=\"3y4ir\"><a href=\"#zotero%7C27937%2FHIPL38QS\">Chastang, Aguilar, and Tannier, “A Named Entity Recognition Model for Medieval Latin Charters.”</a></cite>) and and museum catalogs (<cite id=\"6161c\"><a href=\"#zotero%7C27937%2F68YHDUH6\">“Using Named Entity Recognition to Enhance Access to a Museum Catalog – Document Blog.”</a></cite>) Similar techniques such as sentiment analysis, automated summarization, and machine translation have allowed for more detailed and granular examination of historical source collections, enabling researchers to more accurately pinpoint specific sources most pertinent to their interests. However, each of these extraction techniques usually requires specialized models tailored to each task. LLMs, in contrast, offers the possibility of a all-in-one tool for performing various forms of data extraction in a single inference.\n",
    "\n",
    "To demonstrate, in the following code block a LLM extracts metadata from the earlier oral history transcription and the OCR correction through use of a another prompt containing examples for the LLM to emulate. For each source the LLM will offer a brief summary, perform sentiment analysis, and extract keywords for NER classifications in both English and German. This data is then structured into a machine-usable format as a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "citation-manager": {
     "citations": {
      "7amub": [
       {
        "id": "27937/LC63DETW",
        "source": "zotero"
       }
      ],
      "kwh7q": [
       {
        "id": "27937/Z44J4BKC",
        "source": "zotero"
       }
      ],
      "l0c94": [
       {
        "id": "27937/5ED45HQE",
        "source": "zotero"
       }
      ],
      "mfahj": [
       {
        "id": "27937/LC63DETW",
        "source": "zotero"
       }
      ],
      "z20ld": [
       {
        "id": "27937/5ED45HQE",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "outputs": [],
   "source": [
    "# code block - API call via prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "0p0a5": [
       {
        "id": "27937/LC63DETW",
        "source": "zotero"
       }
      ],
      "k4zh5": [
       {
        "id": "27937/5ED45HQE",
        "source": "zotero"
       }
      ],
      "tqis9": [
       {
        "id": "27937/Z44J4BKC",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "While neither the Whisper transcript nor the OCR correction were error-free, these errors did not prevent the LLM from successfully extracting relevant data in a structured JSON format. Further refinement of the prompt and incorporating more task-specific examples could improve the consistency and fidelity of such outputs. Additionally, fine-tuning LLM models for particular NER tasks and specific datasets can reduce misclassifications and the extraction of irrelevant entities. Researchers in various fields are already applying these techniques to extract data from multilingual historic text collections (<cite id=\"k4zh5\"><a href=\"#zotero%7C27937%2F5ED45HQE\">González-Gallardo et al., “Leveraging Open Large Language Models for Historical Named Entity Recognition.”</a></cite>), as well in other fields for sources as varied as scientific papers (<cite id=\"0p0a5\"><a href=\"#zotero%7C27937%2FLC63DETW\">Dagdelen et al., “Structured Information Extraction from Scientific Text with Large Language Models.”</a></cite>), and electronic health records. (<cite id=\"tqis9\"><a href=\"#zotero%7C27937%2FZ44J4BKC\">Hu et al., “Improving Large Language Models for Clinical Named Entity Recognition via Prompt Engineering.”</a></cite>) The implications of using LLMs for data extraction are significant. Digital historians often spend considerable time processing primary sources manually, but LLMs can streamline this process by automating the extraction of structured data, offering both speed and scalability. The multilingual capabilities of these models also opens up new avenues for comparative historical analysis across language barriers.\n",
    "\n",
    "By streamlining tasks such as transcription, text correction, and metadata generation, LLMs can significantly reduce the workload of creating “tidy datasets”, enabling historians to focus on interpreting data instead of cleaning it. To be sure, this approach risks encoding hallucinations into the foundations of a data collection, and as emphasized in the previous case studies, human review remains essential for the most trustworthy results. But with proper refinement, LLM-driven metadata extraction can prove a useful method for engaging with vast archival collections in new ways. Indeed, scholars are increasingly leveraging LLMs within larger computational systems to power new forms of scholarship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "31iwl": [
       {
        "id": "27937/38C5LZCI",
        "source": "zotero"
       }
      ],
      "cwwxs": [
       {
        "id": "27937/P2KVKTMZ",
        "source": "zotero"
       }
      ],
      "j022d": [
       {
        "id": "27937/7D6BEHLB",
        "source": "zotero"
       }
      ],
      "j39fn": [
       {
        "id": "27937/MYBFNHF8",
        "source": "zotero"
       }
      ],
      "k7j4i": [
       {
        "id": "27937/ECQ4J8E9",
        "source": "zotero"
       }
      ],
      "rfj7w": [
       {
        "id": "27937/RJTNQXZP",
        "source": "zotero"
       }
      ],
      "usvx1": [
       {
        "id": "27937/HGR9QB96",
        "source": "zotero"
       }
      ],
      "yphfo": [
       {
        "id": "27937/ENMGUHSL",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "3 Case Study - RAG\n",
    "\n",
    "<cite id=\"k7j4i\"><a href=\"#zotero%7C27937%2FECQ4J8E9\">Lewis et al., “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.”</a></cite>\n",
    "\n",
    "<cite id=\"j022d\"><a href=\"#zotero%7C27937%2F7D6BEHLB\">Blankenship, Connell, and Dombrowski, “Understanding and Creating Word Embeddings.”</a></cite>\n",
    "\n",
    "<cite id=\"cwwxs\"><a href=\"#zotero%7C27937%2FP2KVKTMZ\">Hutchinson, “Nicolay: Exploring the Speeches of Abraham Lincoln with AI.”</a></cite>\n",
    "\n",
    "<cite id=\"usvx1\"><a href=\"#zotero%7C27937%2FHGR9QB96\">“Presidential Speeches | Miller Center.”</a></cite>\n",
    "\n",
    "Post Nicolay Response\n",
    "\n",
    "<cite id=\"31iwl\"><a href=\"#zotero%7C27937%2F38C5LZCI\">“Google AI Search Tells Users to Glue Pizza and Eat Rocks.”</a></cite>\n",
    "\n",
    "<cite id=\"yphfo\"><a href=\"#zotero%7C27937%2FENMGUHSL\">Li, <i>Lifan0127/Ai-Research-Assistant</i>.</a></cite>\n",
    "\n",
    "<cite id=\"j39fn\"><a href=\"#zotero%7C27937%2FMYBFNHF8\">“WARC-GPT.”</a></cite>\n",
    "\n",
    "<cite id=\"rfj7w\"><a href=\"#zotero%7C27937%2FRJTNQXZP\">Shao et al., “Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models.”</a></cite>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "7s56c": [
       {
        "id": "27937/CXURVMLQ",
        "source": "zotero"
       }
      ],
      "ansdl": [
       {
        "id": "27937/XQYUJV5F",
        "source": "zotero"
       }
      ],
      "b3ukt": [
       {
        "id": "27937/YZQEASUC",
        "source": "zotero"
       }
      ],
      "cekc5": [
       {
        "id": "27937/2LKXDMZD",
        "source": "zotero"
       }
      ],
      "ed4sh": [
       {
        "id": "27937/I363EKXY",
        "source": "zotero"
       }
      ],
      "gh8cw": [
       {
        "id": "27937/VHJBTADE",
        "source": "zotero"
       }
      ],
      "or8nq": [
       {
        "id": "27937/9CA225ZV",
        "source": "zotero"
       }
      ],
      "qqqlh": [
       {
        "id": "27937/XBWIZZJJ",
        "source": "zotero"
       }
      ],
      "ra4qf": [
       {
        "id": "27937/KPPP2BAQ",
        "source": "zotero"
       }
      ],
      "wnwa8": [
       {
        "id": "27937/BN44JR8V",
        "source": "zotero"
       }
      ],
      "xsk3k": [
       {
        "id": "27937/82YIALT5",
        "source": "zotero"
       }
      ]
     }
    }
   },
   "source": [
    "Conclusion\n",
    "\n",
    "<cite id=\"wnwa8\"><a href=\"#zotero%7C27937%2FBN44JR8V\">Underwood, “Mapping the Latent Spaces of Culture.”</a></cite>\n",
    "\n",
    "Atlantic article \"Essay is Dead\"\n",
    "\n",
    "<cite id=\"b3ukt\"><a href=\"#zotero%7C27937%2FYZQEASUC\">“MLA-CCCC Joint Task Force on Writing and AI.”</a></cite>\n",
    "\n",
    "<cite id=\"ansdl\"><a href=\"#zotero%7C27937%2FXQYUJV5F\">Meadows and Sternfeld, “Artificial Intelligence and the Practice of History.”</a></cite>\n",
    "\n",
    "<cite id=\"7s56c\"><a href=\"#zotero%7C27937%2FCXURVMLQ\">Vee, Laquintano, and Schnitzler, “TextGenEd Exhibit.”</a></cite>\n",
    "\n",
    "<cite id=\"cekc5\"><a href=\"#zotero%7C27937%2F2LKXDMZD\">“Simulating History with ChatGPT - by Benjamin Breen.”</a></cite>\n",
    "\n",
    "<cite id=\"ra4qf\"><a href=\"#zotero%7C27937%2FKPPP2BAQ\">“Chatbot That Lets You Talk to Jesus and Hitler Is Latest AI Controversy.”</a></cite>\n",
    "\n",
    "<cite id=\"xsk3k\"><a href=\"#zotero%7C27937%2F82YIALT5\">Cui, Li, and Zhou, “Can AI Replace Human Subjects?”</a></cite>\n",
    "\n",
    "<cite id=\"ed4sh\"><a href=\"#zotero%7C27937%2FI363EKXY\">Xie et al., “Can Large Language Model Agents Simulate Human Trust Behaviors?”</a></cite>\n",
    "\n",
    "<cite id=\"or8nq\"><a href=\"#zotero%7C27937%2F9CA225ZV\">Stade et al., “Large Language Models Could Change the Future of Behavioral Healthcare.”</a></cite>\n",
    "\n",
    "<cite id=\"qqqlh\"><a href=\"#zotero%7C27937%2FXBWIZZJJ\">Park et al., “Generative Agents.”</a></cite>\n",
    "\n",
    "<cite id=\"gh8cw\"><a href=\"#zotero%7C27937%2FVHJBTADE\">Lepore, <i>If Then</i>.</a></cite>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "This is a hermeneutic paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jdh": {
     "module": "object",
     "object": {
      "source": [
       "table 1: label table 1"
      ]
     }
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "table-1"
    ]
   },
   "source": [
    "Editor|1641|1798|1916\n",
    "---|---|---|---\n",
    "Senan|0.55|0.4|0.3\n",
    "Henry|0.71|0.5|0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "hidden"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your Python version\n",
    "from platform import python_version\n",
    "python_version()\n",
    "\n",
    "#!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pandas package needs to be added to the requirements.txt 's file \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PredominantDegree</th>\n",
       "      <th>HighestDegree</th>\n",
       "      <th>FundingModel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Geography</th>\n",
       "      <th>AdmissionRate</th>\n",
       "      <th>ACTMedian</th>\n",
       "      <th>SATAverage</th>\n",
       "      <th>AverageCost</th>\n",
       "      <th>Expenditure</th>\n",
       "      <th>AverageFacultySalary</th>\n",
       "      <th>MedianDebt</th>\n",
       "      <th>AverageAgeofEntry</th>\n",
       "      <th>MedianFamilyIncome</th>\n",
       "      <th>MedianEarnings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>17</td>\n",
       "      <td>823</td>\n",
       "      <td>18888</td>\n",
       "      <td>7459</td>\n",
       "      <td>7079</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>20.629999</td>\n",
       "      <td>29039.0</td>\n",
       "      <td>27000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>25</td>\n",
       "      <td>1146</td>\n",
       "      <td>19990</td>\n",
       "      <td>17208</td>\n",
       "      <td>10170</td>\n",
       "      <td>16250.0</td>\n",
       "      <td>22.670000</td>\n",
       "      <td>34909.0</td>\n",
       "      <td>37200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>26</td>\n",
       "      <td>1180</td>\n",
       "      <td>20306</td>\n",
       "      <td>9352</td>\n",
       "      <td>9341</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>23.190001</td>\n",
       "      <td>39766.0</td>\n",
       "      <td>41500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>17</td>\n",
       "      <td>830</td>\n",
       "      <td>17400</td>\n",
       "      <td>7393</td>\n",
       "      <td>6557</td>\n",
       "      <td>15854.5</td>\n",
       "      <td>20.889999</td>\n",
       "      <td>24029.5</td>\n",
       "      <td>22400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The University of Alabama</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Small City</td>\n",
       "      <td>0.5655</td>\n",
       "      <td>26</td>\n",
       "      <td>1171</td>\n",
       "      <td>26717</td>\n",
       "      <td>9817</td>\n",
       "      <td>9605</td>\n",
       "      <td>17750.0</td>\n",
       "      <td>20.770000</td>\n",
       "      <td>58976.0</td>\n",
       "      <td>39200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>University of Connecticut-Avery Point</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>New England</td>\n",
       "      <td>Mid-size Suburb</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>24</td>\n",
       "      <td>1020</td>\n",
       "      <td>12946</td>\n",
       "      <td>11730</td>\n",
       "      <td>14803</td>\n",
       "      <td>18983.0</td>\n",
       "      <td>20.120001</td>\n",
       "      <td>86510.0</td>\n",
       "      <td>49700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>University of Connecticut-Stamford</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>New England</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>21</td>\n",
       "      <td>1017</td>\n",
       "      <td>13028</td>\n",
       "      <td>4958</td>\n",
       "      <td>14803</td>\n",
       "      <td>18983.0</td>\n",
       "      <td>20.120001</td>\n",
       "      <td>86510.0</td>\n",
       "      <td>49700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>California State University-Channel Islands</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Far West</td>\n",
       "      <td>Mid-size Suburb</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>20</td>\n",
       "      <td>954</td>\n",
       "      <td>22570</td>\n",
       "      <td>12026</td>\n",
       "      <td>8434</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>32103.0</td>\n",
       "      <td>35800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>DigiPen Institute of Technology</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Private For-Profit</td>\n",
       "      <td>Far West</td>\n",
       "      <td>Small City</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>28</td>\n",
       "      <td>1225</td>\n",
       "      <td>37848</td>\n",
       "      <td>5998</td>\n",
       "      <td>7659</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>21.209999</td>\n",
       "      <td>68233.0</td>\n",
       "      <td>72800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Neumont University</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Private For-Profit</td>\n",
       "      <td>Rocky Mountains</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.7997</td>\n",
       "      <td>25</td>\n",
       "      <td>1104</td>\n",
       "      <td>37379</td>\n",
       "      <td>3298</td>\n",
       "      <td>6991</td>\n",
       "      <td>22313.0</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>39241.0</td>\n",
       "      <td>37300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1294 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name PredominantDegree  \\\n",
       "0                        Alabama A & M University        Bachelor's   \n",
       "1             University of Alabama at Birmingham        Bachelor's   \n",
       "2             University of Alabama in Huntsville        Bachelor's   \n",
       "3                        Alabama State University        Bachelor's   \n",
       "4                       The University of Alabama        Bachelor's   \n",
       "...                                           ...               ...   \n",
       "1289        University of Connecticut-Avery Point        Bachelor's   \n",
       "1290           University of Connecticut-Stamford        Bachelor's   \n",
       "1291  California State University-Channel Islands        Bachelor's   \n",
       "1292              DigiPen Institute of Technology        Bachelor's   \n",
       "1293                           Neumont University        Bachelor's   \n",
       "\n",
       "     HighestDegree        FundingModel           Region        Geography  \\\n",
       "0         Graduate              Public        Southeast    Mid-size City   \n",
       "1         Graduate              Public        Southeast    Mid-size City   \n",
       "2         Graduate              Public        Southeast    Mid-size City   \n",
       "3         Graduate              Public        Southeast    Mid-size City   \n",
       "4         Graduate              Public        Southeast       Small City   \n",
       "...            ...                 ...              ...              ...   \n",
       "1289      Graduate              Public      New England  Mid-size Suburb   \n",
       "1290      Graduate              Public      New England    Mid-size City   \n",
       "1291      Graduate              Public         Far West  Mid-size Suburb   \n",
       "1292      Graduate  Private For-Profit         Far West       Small City   \n",
       "1293    Bachelor's  Private For-Profit  Rocky Mountains    Mid-size City   \n",
       "\n",
       "      AdmissionRate  ACTMedian  SATAverage  AverageCost  Expenditure  \\\n",
       "0            0.8989         17         823        18888         7459   \n",
       "1            0.8673         25        1146        19990        17208   \n",
       "2            0.8062         26        1180        20306         9352   \n",
       "3            0.5125         17         830        17400         7393   \n",
       "4            0.5655         26        1171        26717         9817   \n",
       "...             ...        ...         ...          ...          ...   \n",
       "1289         0.5940         24        1020        12946        11730   \n",
       "1290         0.4107         21        1017        13028         4958   \n",
       "1291         0.6443         20         954        22570        12026   \n",
       "1292         0.6635         28        1225        37848         5998   \n",
       "1293         0.7997         25        1104        37379         3298   \n",
       "\n",
       "      AverageFacultySalary  MedianDebt  AverageAgeofEntry  MedianFamilyIncome  \\\n",
       "0                     7079     19500.0          20.629999             29039.0   \n",
       "1                    10170     16250.0          22.670000             34909.0   \n",
       "2                     9341     16500.0          23.190001             39766.0   \n",
       "3                     6557     15854.5          20.889999             24029.5   \n",
       "4                     9605     17750.0          20.770000             58976.0   \n",
       "...                    ...         ...                ...                 ...   \n",
       "1289                 14803     18983.0          20.120001             86510.0   \n",
       "1290                 14803     18983.0          20.120001             86510.0   \n",
       "1291                  8434     12500.0          24.850000             32103.0   \n",
       "1292                  7659     19000.0          21.209999             68233.0   \n",
       "1293                  6991     22313.0          24.750000             39241.0   \n",
       "\n",
       "      MedianEarnings  \n",
       "0              27000  \n",
       "1              37200  \n",
       "2              41500  \n",
       "3              22400  \n",
       "4              39200  \n",
       "...              ...  \n",
       "1289           49700  \n",
       "1290           49700  \n",
       "1291           35800  \n",
       "1292           72800  \n",
       "1293           37300  \n",
       "\n",
       "[1294 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/lux-org/lux-datasets/master/data/college.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "citation-manager": {
   "items": {
    "zotero": {
     "27937/2LKXDMZD": {
      "URL": "https://resobscura.substack.com/p/simulating-history-with-chatgpt",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         25
        ]
       ]
      },
      "id": "27937/2LKXDMZD",
      "system_id": "zotero|27937/2LKXDMZD",
      "title": "Simulating History with ChatGPT - by Benjamin Breen",
      "type": "article"
     },
     "27937/38C5LZCI": {
      "URL": "https://www.bbc.com/news/articles/cd11gzejgz4o",
      "abstract": "Google has defended the answers given by AI Overview, describing them as \"isolated examples\".",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "id": "27937/38C5LZCI",
      "language": "en-GB",
      "system_id": "zotero|27937/38C5LZCI",
      "title": "Google AI search tells users to glue pizza and eat rocks",
      "type": "webpage"
     },
     "27937/56EE9N63": {
      "URL": "http://arxiv.org/abs/2206.07682",
      "abstract": "Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence implies that additional scaling could further expand the range of capabilities of language models.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         27
        ]
       ]
      },
      "author": [
       {
        "family": "Wei",
        "given": "Jason"
       },
       {
        "family": "Tay",
        "given": "Yi"
       },
       {
        "family": "Bommasani",
        "given": "Rishi"
       },
       {
        "family": "Raffel",
        "given": "Colin"
       },
       {
        "family": "Zoph",
        "given": "Barret"
       },
       {
        "family": "Borgeaud",
        "given": "Sebastian"
       },
       {
        "family": "Yogatama",
        "given": "Dani"
       },
       {
        "family": "Bosma",
        "given": "Maarten"
       },
       {
        "family": "Zhou",
        "given": "Denny"
       },
       {
        "family": "Metzler",
        "given": "Donald"
       },
       {
        "family": "Chi",
        "given": "Ed H."
       },
       {
        "family": "Hashimoto",
        "given": "Tatsunori"
       },
       {
        "family": "Vinyals",
        "given": "Oriol"
       },
       {
        "family": "Liang",
        "given": "Percy"
       },
       {
        "family": "Dean",
        "given": "Jeff"
       },
       {
        "family": "Fedus",
        "given": "William"
       }
      ],
      "id": "27937/56EE9N63",
      "issued": {
       "date-parts": [
        [
         2022,
         10,
         26
        ]
       ]
      },
      "note": "arXiv:2206.07682 [cs]",
      "number": "arXiv:2206.07682",
      "publisher": "arXiv",
      "system_id": "zotero|27937/56EE9N63",
      "title": "Emergent Abilities of Large Language Models",
      "type": "article"
     },
     "27937/58X69RSW": {
      "URL": "http://arxiv.org/abs/2404.14219",
      "abstract": "We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. Our training dataset is a scaled-up version of the one used for phi-2, composed of heavily filtered publicly available web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide parameter-scaling results with a 7B, 14B models trained for 4.8T tokens, called phi-3-small, phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75%, 78% on MMLU, and 8.7, 8.9 on MT-bench). To enhance multilingual, multimodal, and long-context capabilities, we introduce three models in the phi-3.5 series: phi-3.5-mini, phi-3.5-MoE, and phi-3.5-Vision. The phi-3.5-MoE, a 16 x 3.8B MoE model with 6.6 billion active parameters, achieves superior performance in language reasoning, math, and code tasks compared to other open-source models of similar scale, such as Llama 3.1 and the Mixtral series, and on par with Gemini-1.5-Flash and GPT-4o-mini. Meanwhile, phi-3.5-Vision, a 4.2 billion parameter model derived from phi-3.5-mini, excels in reasoning tasks and is adept at handling both single-image and text prompts, as well as multi-image and text prompts.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         14
        ]
       ]
      },
      "author": [
       {
        "family": "Abdin",
        "given": "Marah"
       },
       {
        "family": "Aneja",
        "given": "Jyoti"
       },
       {
        "family": "Awadalla",
        "given": "Hany"
       },
       {
        "family": "Awadallah",
        "given": "Ahmed"
       },
       {
        "family": "Awan",
        "given": "Ammar Ahmad"
       },
       {
        "family": "Bach",
        "given": "Nguyen"
       },
       {
        "family": "Bahree",
        "given": "Amit"
       },
       {
        "family": "Bakhtiari",
        "given": "Arash"
       },
       {
        "family": "Bao",
        "given": "Jianmin"
       },
       {
        "family": "Behl",
        "given": "Harkirat"
       },
       {
        "family": "Benhaim",
        "given": "Alon"
       },
       {
        "family": "Bilenko",
        "given": "Misha"
       },
       {
        "family": "Bjorck",
        "given": "Johan"
       },
       {
        "family": "Bubeck",
        "given": "Sébastien"
       },
       {
        "family": "Cai",
        "given": "Martin"
       },
       {
        "family": "Cai",
        "given": "Qin"
       },
       {
        "family": "Chaudhary",
        "given": "Vishrav"
       },
       {
        "family": "Chen",
        "given": "Dong"
       },
       {
        "family": "Chen",
        "given": "Dongdong"
       },
       {
        "family": "Chen",
        "given": "Weizhu"
       },
       {
        "family": "Chen",
        "given": "Yen-Chun"
       },
       {
        "family": "Chen",
        "given": "Yi-Ling"
       },
       {
        "family": "Cheng",
        "given": "Hao"
       },
       {
        "family": "Chopra",
        "given": "Parul"
       },
       {
        "family": "Dai",
        "given": "Xiyang"
       },
       {
        "family": "Dixon",
        "given": "Matthew"
       },
       {
        "family": "Eldan",
        "given": "Ronen"
       },
       {
        "family": "Fragoso",
        "given": "Victor"
       },
       {
        "family": "Gao",
        "given": "Jianfeng"
       },
       {
        "family": "Gao",
        "given": "Mei"
       },
       {
        "family": "Gao",
        "given": "Min"
       },
       {
        "family": "Garg",
        "given": "Amit"
       },
       {
        "family": "Giorno",
        "given": "Allie Del"
       },
       {
        "family": "Goswami",
        "given": "Abhishek"
       },
       {
        "family": "Gunasekar",
        "given": "Suriya"
       },
       {
        "family": "Haider",
        "given": "Emman"
       },
       {
        "family": "Hao",
        "given": "Junheng"
       },
       {
        "family": "Hewett",
        "given": "Russell J."
       },
       {
        "family": "Hu",
        "given": "Wenxiang"
       },
       {
        "family": "Huynh",
        "given": "Jamie"
       },
       {
        "family": "Iter",
        "given": "Dan"
       },
       {
        "family": "Jacobs",
        "given": "Sam Ade"
       },
       {
        "family": "Javaheripi",
        "given": "Mojan"
       },
       {
        "family": "Jin",
        "given": "Xin"
       },
       {
        "family": "Karampatziakis",
        "given": "Nikos"
       },
       {
        "family": "Kauffmann",
        "given": "Piero"
       },
       {
        "family": "Khademi",
        "given": "Mahoud"
       },
       {
        "family": "Kim",
        "given": "Dongwoo"
       },
       {
        "family": "Kim",
        "given": "Young Jin"
       },
       {
        "family": "Kurilenko",
        "given": "Lev"
       },
       {
        "family": "Lee",
        "given": "James R."
       },
       {
        "family": "Lee",
        "given": "Yin Tat"
       },
       {
        "family": "Li",
        "given": "Yuanzhi"
       },
       {
        "family": "Li",
        "given": "Yunsheng"
       },
       {
        "family": "Liang",
        "given": "Chen"
       },
       {
        "family": "Liden",
        "given": "Lars"
       },
       {
        "family": "Lin",
        "given": "Xihui"
       },
       {
        "family": "Lin",
        "given": "Zeqi"
       },
       {
        "family": "Liu",
        "given": "Ce"
       },
       {
        "family": "Liu",
        "given": "Liyuan"
       },
       {
        "family": "Liu",
        "given": "Mengchen"
       },
       {
        "family": "Liu",
        "given": "Weishung"
       },
       {
        "family": "Liu",
        "given": "Xiaodong"
       },
       {
        "family": "Luo",
        "given": "Chong"
       },
       {
        "family": "Madan",
        "given": "Piyush"
       },
       {
        "family": "Mahmoudzadeh",
        "given": "Ali"
       },
       {
        "family": "Majercak",
        "given": "David"
       },
       {
        "family": "Mazzola",
        "given": "Matt"
       },
       {
        "family": "Mendes",
        "given": "Caio César Teodoro"
       },
       {
        "family": "Mitra",
        "given": "Arindam"
       },
       {
        "family": "Modi",
        "given": "Hardik"
       },
       {
        "family": "Nguyen",
        "given": "Anh"
       },
       {
        "family": "Norick",
        "given": "Brandon"
       },
       {
        "family": "Patra",
        "given": "Barun"
       },
       {
        "family": "Perez-Becker",
        "given": "Daniel"
       },
       {
        "family": "Portet",
        "given": "Thomas"
       },
       {
        "family": "Pryzant",
        "given": "Reid"
       },
       {
        "family": "Qin",
        "given": "Heyang"
       },
       {
        "family": "Radmilac",
        "given": "Marko"
       },
       {
        "family": "Ren",
        "given": "Liliang"
       },
       {
        "family": "Rosa",
        "given": "Gustavo de"
       },
       {
        "family": "Rosset",
        "given": "Corby"
       },
       {
        "family": "Roy",
        "given": "Sambudha"
       },
       {
        "family": "Ruwase",
        "given": "Olatunji"
       },
       {
        "family": "Saarikivi",
        "given": "Olli"
       },
       {
        "family": "Saied",
        "given": "Amin"
       },
       {
        "family": "Salim",
        "given": "Adil"
       },
       {
        "family": "Santacroce",
        "given": "Michael"
       },
       {
        "family": "Shah",
        "given": "Shital"
       },
       {
        "family": "Shang",
        "given": "Ning"
       },
       {
        "family": "Sharma",
        "given": "Hiteshi"
       },
       {
        "family": "Shen",
        "given": "Yelong"
       },
       {
        "family": "Shukla",
        "given": "Swadheen"
       },
       {
        "family": "Song",
        "given": "Xia"
       },
       {
        "family": "Tanaka",
        "given": "Masahiro"
       },
       {
        "family": "Tupini",
        "given": "Andrea"
       },
       {
        "family": "Vaddamanu",
        "given": "Praneetha"
       },
       {
        "family": "Wang",
        "given": "Chunyu"
       },
       {
        "family": "Wang",
        "given": "Guanhua"
       },
       {
        "family": "Wang",
        "given": "Lijuan"
       },
       {
        "family": "Wang",
        "given": "Shuohang"
       },
       {
        "family": "Wang",
        "given": "Xin"
       },
       {
        "family": "Wang",
        "given": "Yu"
       },
       {
        "family": "Ward",
        "given": "Rachel"
       },
       {
        "family": "Wen",
        "given": "Wen"
       },
       {
        "family": "Witte",
        "given": "Philipp"
       },
       {
        "family": "Wu",
        "given": "Haiping"
       },
       {
        "family": "Wu",
        "given": "Xiaoxia"
       },
       {
        "family": "Wyatt",
        "given": "Michael"
       },
       {
        "family": "Xiao",
        "given": "Bin"
       },
       {
        "family": "Xu",
        "given": "Can"
       },
       {
        "family": "Xu",
        "given": "Jiahang"
       },
       {
        "family": "Xu",
        "given": "Weijian"
       },
       {
        "family": "Xue",
        "given": "Jilong"
       },
       {
        "family": "Yadav",
        "given": "Sonali"
       },
       {
        "family": "Yang",
        "given": "Fan"
       },
       {
        "family": "Yang",
        "given": "Jianwei"
       },
       {
        "family": "Yang",
        "given": "Yifan"
       },
       {
        "family": "Yang",
        "given": "Ziyi"
       },
       {
        "family": "Yu",
        "given": "Donghan"
       },
       {
        "family": "Yuan",
        "given": "Lu"
       },
       {
        "family": "Zhang",
        "given": "Chenruidong"
       },
       {
        "family": "Zhang",
        "given": "Cyril"
       },
       {
        "family": "Zhang",
        "given": "Jianwen"
       },
       {
        "family": "Zhang",
        "given": "Li Lyna"
       },
       {
        "family": "Zhang",
        "given": "Yi"
       },
       {
        "family": "Zhang",
        "given": "Yue"
       },
       {
        "family": "Zhang",
        "given": "Yunan"
       },
       {
        "family": "Zhou",
        "given": "Xiren"
       }
      ],
      "id": "27937/58X69RSW",
      "issued": {
       "date-parts": [
        [
         2024,
         8,
         30
        ]
       ]
      },
      "note": "arXiv:2404.14219",
      "number": "arXiv:2404.14219",
      "publisher": "arXiv",
      "shortTitle": "Phi-3 Technical Report",
      "system_id": "zotero|27937/58X69RSW",
      "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
      "type": "article"
     },
     "27937/5AL5LZ2K": {
      "URL": "https://dr-hutchinson-what-do-ais-know-about-history-app-i3l5jo.streamlit.app/",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         1
        ]
       ]
      },
      "id": "27937/5AL5LZ2K",
      "system_id": "zotero|27937/5AL5LZ2K",
      "title": "What Do AIs Know About History? A Digital History Experiment by Daniel Hutchinson · Streamlit",
      "type": "webpage"
     },
     "27937/5ED45HQE": {
      "URL": "https://univ-rochelle.hal.science/hal-04662000",
      "abstract": "The efficacy of large-scale language models (LLMs) as few-shot learners has dominated the field of natural language processing, achieving state-of-the-art performance in most tasks, including named entity recognition (NER) for contemporary texts. However, exploration of NER in historical collections (e.g., historical newspapers and classical commentaries) remains limited. This presents a greater challenge as historical texts are often noisy due to storage conditions, OCR extraction, and spelling variation. In this paper, we conduct an empirical evaluation comparing different Instruct variants of open-access and open-sourced LLMs using prompt engineering through deductive (with guidelines) and inductive (without guidelines) approaches against the fully supervised benchmarks. In addition, we study how the interaction between the Instruct model and the user impacts the entity prediction. We conduct reproducible experiments using an easy-to-implement mechanism on publicly available historical collections covering three languages (i.e., English, French, and German) with code-switching on Ancient Greek and four open Instruct models. The results show that Instruct models encounter multiple difficulties handling the noisy input documents, scoring lower than fine-tuned dedicated NER systems, yet the resulting predictions provide entities that can be used in further tagging processes by human annotators.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "author": [
       {
        "family": "González-Gallardo",
        "given": "Carlos-Emiliano"
       },
       {
        "family": "Hanh",
        "given": "Tran Thi Hong"
       },
       {
        "family": "Hamdi",
        "given": "Ahmed"
       },
       {
        "family": "Doucet",
        "given": "Antoine"
       }
      ],
      "event": "The 28th International Conference on Theory and Practice of Digital Libraries",
      "id": "27937/5ED45HQE",
      "issued": {
       "date-parts": [
        [
         2024,
         9,
         24
        ]
       ]
      },
      "language": "en",
      "system_id": "zotero|27937/5ED45HQE",
      "title": "Leveraging Open Large Language Models for Historical Named Entity Recognition",
      "type": "paper-conference"
     },
     "27937/5G5LJCLC": {
      "URL": "https://github.com/dair-ai/Prompt-Engineering-Guide",
      "abstract": "🐙 Guides, papers, lecture, notebooks and resources for prompt engineering",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         25
        ]
       ]
      },
      "author": [
       {
        "family": "Saravia",
        "given": "Elvis"
       }
      ],
      "id": "27937/5G5LJCLC",
      "issued": {
       "date-parts": [
        [
         2022,
         12
        ]
       ]
      },
      "note": "Publication Title: https://github.com/dair-ai/Prompt-Engineering-Guide\noriginal-date: 2022-12-16T16:04:50Z",
      "system_id": "zotero|27937/5G5LJCLC",
      "title": "Prompt Engineering Guide",
      "type": "book"
     },
     "27937/5GTQD5W9": {
      "URL": "https://excavating.ai",
      "abstract": "An investigation into the politics of training sets, and the fundamental problems with classifying humans.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "container-title": "-",
      "id": "27937/5GTQD5W9",
      "language": "en-US",
      "system_id": "zotero|27937/5GTQD5W9",
      "title": "Excavating AI",
      "type": "webpage"
     },
     "27937/5YDNQS4V": {
      "URL": "https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/",
      "abstract": "Algorithms must be responsibly created to avoid discrimination and unethical applications.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "author": [
       {
        "family": "Barton",
        "given": "Nicol Turner Lee, Paul Resnick, and Genie"
       }
      ],
      "container-title": "Brookings",
      "id": "27937/5YDNQS4V",
      "issued": {
       "date-parts": [
        [
         2019,
         5,
         22
        ]
       ]
      },
      "language": "en-US",
      "shortTitle": "Algorithmic bias detection and mitigation",
      "system_id": "zotero|27937/5YDNQS4V",
      "title": "Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms",
      "type": "post-weblog"
     },
     "27937/68YHDUH6": {
      "URL": "https://blog.ehri-project.eu/2018/08/27/named-entity-recognition/",
      "abstract": "The European Holocaust Research Infrastructure Document Blog",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         15
        ]
       ]
      },
      "id": "27937/68YHDUH6",
      "issued": {
       "date-parts": [
        [
         2018,
         8,
         27
        ]
       ]
      },
      "language": "en-GB",
      "system_id": "zotero|27937/68YHDUH6",
      "title": "Using Named Entity Recognition to Enhance Access to a Museum Catalog – Document Blog",
      "type": "post-weblog"
     },
     "27937/7D6BEHLB": {
      "URL": "https://programminghistorian.org/en/lessons/understanding-creating-word-embeddings",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "author": [
       {
        "family": "Blankenship",
        "given": "Avery"
       },
       {
        "family": "Connell",
        "given": "Sarah"
       },
       {
        "family": "Dombrowski",
        "given": "Quinn"
       }
      ],
      "container-title": "Programming Historian",
      "id": "27937/7D6BEHLB",
      "issued": {
       "date-parts": [
        [
         2024,
         1,
         31
        ]
       ]
      },
      "language": "en",
      "system_id": "zotero|27937/7D6BEHLB",
      "title": "Understanding and Creating Word Embeddings",
      "type": "article-journal"
     },
     "27937/7VHKCH3M": {
      "URL": "http://arxiv.org/abs/2212.04356",
      "abstract": "We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results but in a zero-shot transfer setting without the need for any fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         29
        ]
       ]
      },
      "author": [
       {
        "family": "Radford",
        "given": "Alec"
       },
       {
        "family": "Kim",
        "given": "Jong Wook"
       },
       {
        "family": "Xu",
        "given": "Tao"
       },
       {
        "family": "Brockman",
        "given": "Greg"
       },
       {
        "family": "McLeavey",
        "given": "Christine"
       },
       {
        "family": "Sutskever",
        "given": "Ilya"
       }
      ],
      "id": "27937/7VHKCH3M",
      "issued": {
       "date-parts": [
        [
         2022,
         12,
         6
        ]
       ]
      },
      "note": "arXiv:2212.04356 [cs, eess]",
      "number": "arXiv:2212.04356",
      "publisher": "arXiv",
      "system_id": "zotero|27937/7VHKCH3M",
      "title": "Robust Speech Recognition via Large-Scale Weak Supervision",
      "type": "article"
     },
     "27937/82YIALT5": {
      "DOI": "10.48550/arXiv.2409.00128",
      "URL": "http://arxiv.org/abs/2409.00128",
      "abstract": "Artificial Intelligence (AI) is increasingly being integrated into scientific research, particularly in the social sciences, where understanding human behavior is critical. Large Language Models (LLMs) like GPT-4 have shown promise in replicating human-like responses in various psychological experiments. However, the extent to which LLMs can effectively replace human subjects across diverse experimental contexts remains unclear. Here, we conduct a large-scale study replicating 154 psychological experiments from top social science journals with 618 main effects and 138 interaction effects using GPT-4 as a simulated participant. We find that GPT-4 successfully replicates 76.0 percent of main effects and 47.0 percent of interaction effects observed in the original studies, closely mirroring human responses in both direction and significance. However, only 19.44 percent of GPT-4's replicated confidence intervals contain the original effect sizes, with the majority of replicated effect sizes exceeding the 95 percent confidence interval of the original studies. Additionally, there is a 71.6 percent rate of unexpected significant results where the original studies reported null findings, suggesting potential overestimation or false positives. Our results demonstrate the potential of LLMs as powerful tools in psychological research but also emphasize the need for caution in interpreting AI-driven findings. While LLMs can complement human studies, they cannot yet fully replace the nuanced insights provided by human subjects.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Cui",
        "given": "Ziyan"
       },
       {
        "family": "Li",
        "given": "Ning"
       },
       {
        "family": "Zhou",
        "given": "Huaikang"
       }
      ],
      "id": "27937/82YIALT5",
      "issued": {
       "date-parts": [
        [
         2024,
         9,
         4
        ]
       ]
      },
      "note": "arXiv:2409.00128",
      "number": "arXiv:2409.00128",
      "publisher": "arXiv",
      "shortTitle": "Can AI Replace Human Subjects?",
      "system_id": "zotero|27937/82YIALT5",
      "title": "Can AI Replace Human Subjects? A Large-Scale Replication of Psychological Experiments with LLMs",
      "type": "article"
     },
     "27937/9CA225ZV": {
      "DOI": "10.1038/s44184-024-00056-z",
      "URL": "https://www.nature.com/articles/s44184-024-00056-z",
      "abstract": "Large language models (LLMs) such as Open AI’s GPT-4 (which power ChatGPT) and Google’s Gemini, built on artificial intelligence, hold immense potential to support, augment, or even eventually automate psychotherapy. Enthusiasm about such applications is mounting in the field as well as industry. These developments promise to address insufficient mental healthcare system capacity and scale individual access to personalized treatments. However, clinical psychology is an uncommonly high stakes application domain for AI systems, as responsible and evidence-based therapy requires nuanced expertise. This paper provides a roadmap for the ambitious yet responsible application of clinical LLMs in psychotherapy. First, a technical overview of clinical LLMs is presented. Second, the stages of integration of LLMs into psychotherapy are discussed while highlighting parallels to the development of autonomous vehicle technology. Third, potential applications of LLMs in clinical care, training, and research are discussed, highlighting areas of risk given the complex nature of psychotherapy. Fourth, recommendations for the responsible development and evaluation of clinical LLMs are provided, which include centering clinical science, involving robust interdisciplinary collaboration, and attending to issues like assessment, risk detection, transparency, and bias. Lastly, a vision is outlined for how LLMs might enable a new generation of studies of evidence-based interventions at scale, and how these studies may challenge assumptions about psychotherapy.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Stade",
        "given": "Elizabeth C."
       },
       {
        "family": "Stirman",
        "given": "Shannon Wiltsey"
       },
       {
        "family": "Ungar",
        "given": "Lyle H."
       },
       {
        "family": "Boland",
        "given": "Cody L."
       },
       {
        "family": "Schwartz",
        "given": "H. Andrew"
       },
       {
        "family": "Yaden",
        "given": "David B."
       },
       {
        "family": "Sedoc",
        "given": "João"
       },
       {
        "family": "DeRubeis",
        "given": "Robert J."
       },
       {
        "family": "Willer",
        "given": "Robb"
       },
       {
        "family": "Eichstaedt",
        "given": "Johannes C."
       }
      ],
      "container-title": "npj Mental Health Research",
      "id": "27937/9CA225ZV",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2024,
         4,
         2
        ]
       ]
      },
      "journalAbbreviation": "npj Mental Health Res",
      "language": "en",
      "note": "Publisher: Nature Publishing Group",
      "page": "1-12",
      "shortTitle": "Large language models could change the future of behavioral healthcare",
      "system_id": "zotero|27937/9CA225ZV",
      "title": "Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation",
      "type": "article-journal",
      "volume": "3"
     },
     "27937/9GQG6VFM": {
      "DOI": "10.1145/3571730",
      "URL": "http://arxiv.org/abs/2202.03629",
      "abstract": "Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before. In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions; and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, machine translation, and visual-language generation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.",
      "accessed": {
       "date-parts": [
        [
         2023,
         4,
         3
        ]
       ]
      },
      "author": [
       {
        "family": "Ji",
        "given": "Ziwei"
       },
       {
        "family": "Lee",
        "given": "Nayeon"
       },
       {
        "family": "Frieske",
        "given": "Rita"
       },
       {
        "family": "Yu",
        "given": "Tiezheng"
       },
       {
        "family": "Su",
        "given": "Dan"
       },
       {
        "family": "Xu",
        "given": "Yan"
       },
       {
        "family": "Ishii",
        "given": "Etsuko"
       },
       {
        "family": "Bang",
        "given": "Yejin"
       },
       {
        "family": "Dai",
        "given": "Wenliang"
       },
       {
        "family": "Madotto",
        "given": "Andrea"
       },
       {
        "family": "Fung",
        "given": "Pascale"
       }
      ],
      "container-title": "ACM Computing Surveys",
      "id": "27937/9GQG6VFM",
      "issue": "12",
      "issued": {
       "date-parts": [
        [
         2023,
         12,
         31
        ]
       ]
      },
      "journalAbbreviation": "ACM Comput. Surv.",
      "note": "arXiv:2202.03629 [cs]",
      "page": "1-38",
      "system_id": "zotero|27937/9GQG6VFM",
      "title": "Survey of Hallucination in Natural Language Generation",
      "type": "article-journal",
      "volume": "55"
     },
     "27937/9HF43E58": {
      "URL": "https://www.promptingguide.ai/",
      "abstract": "A Comprehensive Overview of Prompt Engineering",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         23
        ]
       ]
      },
      "id": "27937/9HF43E58",
      "issued": {
       "date-parts": [
        [
         2024,
         9,
         19
        ]
       ]
      },
      "language": "en",
      "system_id": "zotero|27937/9HF43E58",
      "title": "Prompt Engineering Guide",
      "type": "webpage"
     },
     "27937/9T2I7QLM": {
      "URL": "http://arxiv.org/abs/1706.03762",
      "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         25
        ]
       ]
      },
      "author": [
       {
        "family": "Vaswani",
        "given": "Ashish"
       },
       {
        "family": "Shazeer",
        "given": "Noam"
       },
       {
        "family": "Parmar",
        "given": "Niki"
       },
       {
        "family": "Uszkoreit",
        "given": "Jakob"
       },
       {
        "family": "Jones",
        "given": "Llion"
       },
       {
        "family": "Gomez",
        "given": "Aidan N."
       },
       {
        "family": "Kaiser",
        "given": "Lukasz"
       },
       {
        "family": "Polosukhin",
        "given": "Illia"
       }
      ],
      "id": "27937/9T2I7QLM",
      "issued": {
       "date-parts": [
        [
         2023,
         8,
         2
        ]
       ]
      },
      "note": "arXiv:1706.03762",
      "number": "arXiv:1706.03762",
      "publisher": "arXiv",
      "system_id": "zotero|27937/9T2I7QLM",
      "title": "Attention Is All You Need",
      "type": "article"
     },
     "27937/A834FRJL": {
      "URL": "https://github.com/hendrycks/test",
      "abstract": "Measuring Massive Multitask Language Understanding | ICLR 2021",
      "accessed": {
       "date-parts": [
        [
         2023,
         4,
         2
        ]
       ]
      },
      "author": [
       {
        "family": "Hendrycks",
        "given": "Dan"
       }
      ],
      "id": "27937/A834FRJL",
      "issued": {
       "date-parts": [
        [
         2023,
         4,
         2
        ]
       ]
      },
      "note": "original-date: 2020-09-07T23:02:57Z",
      "system_id": "zotero|27937/A834FRJL",
      "title": "Measuring Massive Multitask Language Understanding",
      "type": "book"
     },
     "27937/BD8996H7": {
      "URL": "https://reports.collegeboard.org/media/pdf/program-summary-report-2022.pdf",
      "container-title": "AP Exam Administration Data Archive",
      "id": "27937/BD8996H7",
      "issued": {
       "date-parts": [
        [
         2022
        ]
       ]
      },
      "system_id": "zotero|27937/BD8996H7",
      "title": "Program Summary Report",
      "type": "webpage"
     },
     "27937/BN44JR8V": {
      "URL": "https://hcommons.org/deposits/item/hc:41973/",
      "abstract": "As neural language models begin to change aspects of everyday life, they understandably attract criticism. This position paper was commissioned for a roundtable at Princeton University, dedicated to one of the most influential critiques: \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\" by Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell. \n\nMy paper agrees that neural language models pose a variety of dangers, starting with and not limited to the list in \"Stochastic Parrots.\" But to understand those dangers, I think we need to look beyond the premise that these models mimic \"language understanding\" on an individual level. That may have been what linguists and computer scientists intended them to do. But the models' actual potential (for both good and ill) is more interesting, and will be easier to grasp if we approach them as models of culture. Science-fictional scenarios about robots that become autonomous (or remain mere \"parrots\") are less useful here than humanistic cultural theory.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Underwood",
        "given": "Ted"
       }
      ],
      "id": "27937/BN44JR8V",
      "issued": {
       "date-parts": [
        [
         "2021",
         10,
         20
        ]
       ]
      },
      "language": "en-US",
      "system_id": "zotero|27937/BN44JR8V",
      "title": "Mapping the Latent Spaces of Culture",
      "type": "article-journal"
     },
     "27937/BVBZMR66": {
      "DOI": "10.48550/arXiv.2212.14402",
      "URL": "http://arxiv.org/abs/2212.14402",
      "abstract": "Nearly all jurisdictions in the United States require a professional license exam, commonly referred to as \"the Bar Exam,\" as a precondition for law practice. To even sit for the exam, most jurisdictions require that an applicant completes at least seven years of post-secondary education, including three years at an accredited law school. In addition, most test-takers also undergo weeks to months of further, exam-specific preparation. Despite this significant investment of time and capital, approximately one in five test-takers still score under the rate required to pass the exam on their first try. In the face of a complex task that requires such depth of knowledge, what, then, should we expect of the state of the art in \"AI?\" In this research, we document our experimental evaluation of the performance of OpenAI's `text-davinci-003` model, often-referred to as GPT-3.5, on the multistate multiple choice (MBE) section of the exam. While we find no benefit in fine-tuning over GPT-3.5's zero-shot performance at the scale of our training data, we do find that hyperparameter optimization and prompt engineering positively impacted GPT-3.5's zero-shot performance. For best prompt and parameters, GPT-3.5 achieves a headline correct rate of 50.3% on a complete NCBE MBE practice exam, significantly in excess of the 25% baseline guessing rate, and performs at a passing rate for both Evidence and Torts. GPT-3.5's ranking of responses is also highly-correlated with correctness; its top two and top three choices are correct 71% and 88% of the time, respectively, indicating very strong non-entailment performance. While our ability to interpret these results is limited by nascent scientific understanding of LLMs and the proprietary nature of GPT, we believe that these results strongly suggest that an LLM will pass the MBE component of the Bar Exam in the near future.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         25
        ]
       ]
      },
      "author": [
       {
        "family": "Katz",
        "given": "Daniel Martin"
       }
      ],
      "id": "27937/BVBZMR66",
      "issued": {
       "date-parts": [
        [
         2022,
         12,
         29
        ]
       ]
      },
      "note": "arXiv:2212.14402",
      "number": "arXiv:2212.14402",
      "publisher": "arXiv",
      "system_id": "zotero|27937/BVBZMR66",
      "title": "GPT Takes the Bar Exam",
      "type": "article"
     },
     "27937/BXZEP65G": {
      "URL": "https://cajundiscordian.medium.com/what-is-lamda-and-what-does-it-want-688632134489",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         27
        ]
       ]
      },
      "id": "27937/BXZEP65G",
      "system_id": "zotero|27937/BXZEP65G",
      "title": "What is LaMDA and What Does it Want? | by Blake Lemoine | Medium",
      "type": "webpage"
     },
     "27937/CJYNFHVI": {
      "DOI": "10.1086/ahr/108.3.735",
      "URL": "https://doi.org/10.1086/ahr/108.3.735",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         27
        ]
       ]
      },
      "author": [
       {
        "family": "Rosenzweig",
        "given": "Roy"
       }
      ],
      "container-title": "The American Historical Review",
      "id": "27937/CJYNFHVI",
      "issue": "3",
      "issued": {
       "date-parts": [
        [
         2003,
         6,
         1
        ]
       ]
      },
      "journalAbbreviation": "The American Historical Review",
      "page": "735-762",
      "shortTitle": "Scarcity or Abundance?",
      "system_id": "zotero|27937/CJYNFHVI",
      "title": "Scarcity or Abundance? Preserving the Past in a Digital Era",
      "type": "article-journal",
      "volume": "108"
     },
     "27937/CXURVMLQ": {
      "DOI": "10.37514/TWR-J.2023.1.1.02",
      "URL": "https://wac.colostate.edu/repository/collections/textgened/",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         25
        ]
       ]
      },
      "author": [
       {
        "family": "Vee",
        "given": "Annette"
       },
       {
        "family": "Laquintano",
        "given": "Tim"
       },
       {
        "family": "Schnitzler",
        "given": "Carly"
       }
      ],
      "container-title": "The WAC Repository",
      "id": "27937/CXURVMLQ",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2023
        ]
       ]
      },
      "language": "en",
      "page": "1-100",
      "system_id": "zotero|27937/CXURVMLQ",
      "title": "TextGenEd Exhibit",
      "type": "article-journal",
      "volume": "1"
     },
     "27937/ECQ4J8E9": {
      "DOI": "10.48550/arXiv.2005.11401",
      "URL": "http://arxiv.org/abs/2005.11401",
      "abstract": "Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "author": [
       {
        "family": "Lewis",
        "given": "Patrick"
       },
       {
        "family": "Perez",
        "given": "Ethan"
       },
       {
        "family": "Piktus",
        "given": "Aleksandra"
       },
       {
        "family": "Petroni",
        "given": "Fabio"
       },
       {
        "family": "Karpukhin",
        "given": "Vladimir"
       },
       {
        "family": "Goyal",
        "given": "Naman"
       },
       {
        "family": "Küttler",
        "given": "Heinrich"
       },
       {
        "family": "Lewis",
        "given": "Mike"
       },
       {
        "family": "Yih",
        "given": "Wen-tau"
       },
       {
        "family": "Rocktäschel",
        "given": "Tim"
       },
       {
        "family": "Riedel",
        "given": "Sebastian"
       },
       {
        "family": "Kiela",
        "given": "Douwe"
       }
      ],
      "id": "27937/ECQ4J8E9",
      "issued": {
       "date-parts": [
        [
         2021,
         4,
         12
        ]
       ]
      },
      "note": "arXiv:2005.11401",
      "number": "arXiv:2005.11401",
      "publisher": "arXiv",
      "system_id": "zotero|27937/ECQ4J8E9",
      "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "type": "article"
     },
     "27937/ENMGUHSL": {
      "URL": "https://github.com/lifan0127/ai-research-assistant",
      "abstract": "Aria is Your AI Research Assistant Powered by GPT Large Language Models",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "author": [
       {
        "family": "Li",
        "given": "Fan"
       }
      ],
      "id": "27937/ENMGUHSL",
      "issued": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "note": "original-date: 2023-03-28T01:30:13Z",
      "system_id": "zotero|27937/ENMGUHSL",
      "title": "lifan0127/ai-research-assistant",
      "type": "book"
     },
     "27937/EZNK3CE3": {
      "URL": "http://site.ebrary.com/id/10158052",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         25
        ]
       ]
      },
      "author": [
       {
        "family": "McCorduck",
        "given": "Pamela"
       }
      ],
      "edition": "25th anniversary update",
      "event-place": "Natick, Mass.",
      "id": "27937/EZNK3CE3",
      "issued": {
       "date-parts": [
        [
         2004
        ]
       ]
      },
      "language": "eng",
      "note": "OCLC: 748860627",
      "number-of-pages": "1",
      "publisher": "A.K. Peters",
      "publisher-place": "Natick, Mass.",
      "system_id": "zotero|27937/EZNK3CE3",
      "title": "Machines who think a personal inquiry into the history and prospects of artificial intelligence",
      "type": "book"
     },
     "27937/FMW5DCWM": {
      "URL": "http://arxiv.org/abs/2204.02311",
      "abstract": "Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "author": [
       {
        "family": "Chowdhery",
        "given": "Aakanksha"
       },
       {
        "family": "Narang",
        "given": "Sharan"
       },
       {
        "family": "Devlin",
        "given": "Jacob"
       },
       {
        "family": "Bosma",
        "given": "Maarten"
       },
       {
        "family": "Mishra",
        "given": "Gaurav"
       },
       {
        "family": "Roberts",
        "given": "Adam"
       },
       {
        "family": "Barham",
        "given": "Paul"
       },
       {
        "family": "Chung",
        "given": "Hyung Won"
       },
       {
        "family": "Sutton",
        "given": "Charles"
       },
       {
        "family": "Gehrmann",
        "given": "Sebastian"
       },
       {
        "family": "Schuh",
        "given": "Parker"
       },
       {
        "family": "Shi",
        "given": "Kensen"
       },
       {
        "family": "Tsvyashchenko",
        "given": "Sasha"
       },
       {
        "family": "Maynez",
        "given": "Joshua"
       },
       {
        "family": "Rao",
        "given": "Abhishek"
       },
       {
        "family": "Barnes",
        "given": "Parker"
       },
       {
        "family": "Tay",
        "given": "Yi"
       },
       {
        "family": "Shazeer",
        "given": "Noam"
       },
       {
        "family": "Prabhakaran",
        "given": "Vinodkumar"
       },
       {
        "family": "Reif",
        "given": "Emily"
       },
       {
        "family": "Du",
        "given": "Nan"
       },
       {
        "family": "Hutchinson",
        "given": "Ben"
       },
       {
        "family": "Pope",
        "given": "Reiner"
       },
       {
        "family": "Bradbury",
        "given": "James"
       },
       {
        "family": "Austin",
        "given": "Jacob"
       },
       {
        "family": "Isard",
        "given": "Michael"
       },
       {
        "family": "Gur-Ari",
        "given": "Guy"
       },
       {
        "family": "Yin",
        "given": "Pengcheng"
       },
       {
        "family": "Duke",
        "given": "Toju"
       },
       {
        "family": "Levskaya",
        "given": "Anselm"
       },
       {
        "family": "Ghemawat",
        "given": "Sanjay"
       },
       {
        "family": "Dev",
        "given": "Sunipa"
       },
       {
        "family": "Michalewski",
        "given": "Henryk"
       },
       {
        "family": "Garcia",
        "given": "Xavier"
       },
       {
        "family": "Misra",
        "given": "Vedant"
       },
       {
        "family": "Robinson",
        "given": "Kevin"
       },
       {
        "family": "Fedus",
        "given": "Liam"
       },
       {
        "family": "Zhou",
        "given": "Denny"
       },
       {
        "family": "Ippolito",
        "given": "Daphne"
       },
       {
        "family": "Luan",
        "given": "David"
       },
       {
        "family": "Lim",
        "given": "Hyeontaek"
       },
       {
        "family": "Zoph",
        "given": "Barret"
       },
       {
        "family": "Spiridonov",
        "given": "Alexander"
       },
       {
        "family": "Sepassi",
        "given": "Ryan"
       },
       {
        "family": "Dohan",
        "given": "David"
       },
       {
        "family": "Agrawal",
        "given": "Shivani"
       },
       {
        "family": "Omernick",
        "given": "Mark"
       },
       {
        "family": "Dai",
        "given": "Andrew M."
       },
       {
        "family": "Pillai",
        "given": "Thanumalayan Sankaranarayana"
       },
       {
        "family": "Pellat",
        "given": "Marie"
       },
       {
        "family": "Lewkowycz",
        "given": "Aitor"
       },
       {
        "family": "Moreira",
        "given": "Erica"
       },
       {
        "family": "Child",
        "given": "Rewon"
       },
       {
        "family": "Polozov",
        "given": "Oleksandr"
       },
       {
        "family": "Lee",
        "given": "Katherine"
       },
       {
        "family": "Zhou",
        "given": "Zongwei"
       },
       {
        "family": "Wang",
        "given": "Xuezhi"
       },
       {
        "family": "Saeta",
        "given": "Brennan"
       },
       {
        "family": "Diaz",
        "given": "Mark"
       },
       {
        "family": "Firat",
        "given": "Orhan"
       },
       {
        "family": "Catasta",
        "given": "Michele"
       },
       {
        "family": "Wei",
        "given": "Jason"
       },
       {
        "family": "Meier-Hellstern",
        "given": "Kathy"
       },
       {
        "family": "Eck",
        "given": "Douglas"
       },
       {
        "family": "Dean",
        "given": "Jeff"
       },
       {
        "family": "Petrov",
        "given": "Slav"
       },
       {
        "family": "Fiedel",
        "given": "Noah"
       }
      ],
      "id": "27937/FMW5DCWM",
      "issued": {
       "date-parts": [
        [
         2022,
         10,
         5
        ]
       ]
      },
      "note": "arXiv:2204.02311 [cs]",
      "number": "arXiv:2204.02311",
      "publisher": "arXiv",
      "shortTitle": "PaLM",
      "system_id": "zotero|27937/FMW5DCWM",
      "title": "PaLM: Scaling Language Modeling with Pathways",
      "type": "article"
     },
     "27937/G5ESJ8NI": {
      "URL": "http://arxiv.org/abs/2203.15556",
      "abstract": "We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4$\\times$ more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5% on the MMLU benchmark, greater than a 7% improvement over Gopher.",
      "accessed": {
       "date-parts": [
        [
         2023,
         4,
         2
        ]
       ]
      },
      "author": [
       {
        "family": "Hoffmann",
        "given": "Jordan"
       },
       {
        "family": "Borgeaud",
        "given": "Sebastian"
       },
       {
        "family": "Mensch",
        "given": "Arthur"
       },
       {
        "family": "Buchatskaya",
        "given": "Elena"
       },
       {
        "family": "Cai",
        "given": "Trevor"
       },
       {
        "family": "Rutherford",
        "given": "Eliza"
       },
       {
        "family": "Casas",
        "given": "Diego de Las"
       },
       {
        "family": "Hendricks",
        "given": "Lisa Anne"
       },
       {
        "family": "Welbl",
        "given": "Johannes"
       },
       {
        "family": "Clark",
        "given": "Aidan"
       },
       {
        "family": "Hennigan",
        "given": "Tom"
       },
       {
        "family": "Noland",
        "given": "Eric"
       },
       {
        "family": "Millican",
        "given": "Katie"
       },
       {
        "family": "Driessche",
        "given": "George van den"
       },
       {
        "family": "Damoc",
        "given": "Bogdan"
       },
       {
        "family": "Guy",
        "given": "Aurelia"
       },
       {
        "family": "Osindero",
        "given": "Simon"
       },
       {
        "family": "Simonyan",
        "given": "Karen"
       },
       {
        "family": "Elsen",
        "given": "Erich"
       },
       {
        "family": "Rae",
        "given": "Jack W."
       },
       {
        "family": "Vinyals",
        "given": "Oriol"
       },
       {
        "family": "Sifre",
        "given": "Laurent"
       }
      ],
      "id": "27937/G5ESJ8NI",
      "issued": {
       "date-parts": [
        [
         2022,
         3,
         29
        ]
       ]
      },
      "note": "arXiv:2203.15556 [cs]",
      "number": "arXiv:2203.15556",
      "publisher": "arXiv",
      "system_id": "zotero|27937/G5ESJ8NI",
      "title": "Training Compute-Optimal Large Language Models",
      "type": "article"
     },
     "27937/GJ2EYJWT": {
      "URL": "https://huggingface.co/spaces/openai/whisper",
      "abstract": "Discover amazing ML apps made by the community",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         31
        ]
       ]
      },
      "id": "27937/GJ2EYJWT",
      "system_id": "zotero|27937/GJ2EYJWT",
      "title": "Whisper - a Hugging Face Space by openai",
      "type": "webpage"
     },
     "27937/GSIXPJ7P": {
      "URL": "https://crfm.stanford.edu/2024/05/01/helm-mmlu.html",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         1
        ]
       ]
      },
      "author": [
       {
        "family": "Mai",
        "given": "Yifan"
       },
       {
        "family": "Liang",
        "given": "Percy"
       }
      ],
      "container-title": "Center for Research on Foundation Models, Stanford University",
      "genre": "Blog",
      "id": "27937/GSIXPJ7P",
      "issued": {
       "date-parts": [
        [
         2024,
         5,
         1
        ]
       ]
      },
      "system_id": "zotero|27937/GSIXPJ7P",
      "title": "Massive Multitask Language Understanding (MMLU) on HELM",
      "type": "webpage"
     },
     "27937/H9BUWE28": {
      "DOI": "10.48550/arXiv.2001.08361",
      "URL": "http://arxiv.org/abs/2001.08361",
      "abstract": "We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.",
      "accessed": {
       "date-parts": [
        [
         2024,
         9,
         30
        ]
       ]
      },
      "author": [
       {
        "family": "Kaplan",
        "given": "Jared"
       },
       {
        "family": "McCandlish",
        "given": "Sam"
       },
       {
        "family": "Henighan",
        "given": "Tom"
       },
       {
        "family": "Brown",
        "given": "Tom B."
       },
       {
        "family": "Chess",
        "given": "Benjamin"
       },
       {
        "family": "Child",
        "given": "Rewon"
       },
       {
        "family": "Gray",
        "given": "Scott"
       },
       {
        "family": "Radford",
        "given": "Alec"
       },
       {
        "family": "Wu",
        "given": "Jeffrey"
       },
       {
        "family": "Amodei",
        "given": "Dario"
       }
      ],
      "id": "27937/H9BUWE28",
      "issued": {
       "date-parts": [
        [
         2020,
         1,
         22
        ]
       ]
      },
      "note": "arXiv:2001.08361 [cs, stat]",
      "number": "arXiv:2001.08361",
      "publisher": "arXiv",
      "system_id": "zotero|27937/H9BUWE28",
      "title": "Scaling Laws for Neural Language Models",
      "type": "article"
     },
     "27937/HGR9QB96": {
      "URL": "https://millercenter.org/the-presidency/presidential-speeches",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "id": "27937/HGR9QB96",
      "issued": {
       "date-parts": [
        [
         2016,
         11,
         21
        ]
       ]
      },
      "language": "en",
      "system_id": "zotero|27937/HGR9QB96",
      "title": "Presidential Speeches | Miller Center",
      "type": "webpage"
     },
     "27937/HIPL38QS": {
      "URL": "https://www.digitalhumanities.org/dhq/vol/15/4/000574/000574.html",
      "abstract": "Named entity recognition is an advantageous technique with an increasing presence in digital humanities. In theory, automatic detection and recovery of named entities can provide new ways of looking up unedited information in edited sources and can allow the parsing of a massive amount of data in a short time for supporting historical hypotheses. In this paper, we detail the implementation of a model for automatic named entity recognition in medieval Latin sources and we test its robustness on different datasets. Different models were trained on a vast dataset of Burgundian diplomatic charters from the 9th to 14th centuries and validated by using general and century ad hoc models tested on short sets of Parisian, English, Italian and Spanish charters. We present the results of cross-validation in each case and we discuss the implications of these results for the history of medieval place-names and personal names.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         15
        ]
       ]
      },
      "author": [
       {
        "family": "Chastang",
        "given": "Pierre"
       },
       {
        "family": "Aguilar",
        "given": "Sergio Torres"
       },
       {
        "family": "Tannier",
        "given": "Xavier"
       }
      ],
      "container-title": "Digital Humanities Quarterly",
      "id": "27937/HIPL38QS",
      "issue": "4",
      "issued": {
       "date-parts": [
        [
         2021
        ]
       ]
      },
      "system_id": "zotero|27937/HIPL38QS",
      "title": "A Named Entity Recognition Model for Medieval Latin Charters",
      "type": "article-journal",
      "volume": "15"
     },
     "27937/I2BKP7MN": {
      "URL": "https://www.css.cnrs.fr/using-whisper-to-transcribe-oral-interviews/",
      "abstract": "Site web de l'axe sciences sociales computationnelles du CREST-CNRS. Cours et tutoriels pour l'analyse des données numériques en sciences sociales.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         25
        ]
       ]
      },
      "author": [
       {
        "family": "Schultz",
        "given": "Emilien"
       }
      ],
      "id": "27937/I2BKP7MN",
      "issued": {
       "date-parts": [
        [
         2024,
         2,
         12
        ]
       ]
      },
      "language": "en-US",
      "system_id": "zotero|27937/I2BKP7MN",
      "title": "[Tutorial] Using Whisper to Transcribe Oral Interviews – CSS @ IPP",
      "type": "post-weblog"
     },
     "27937/I363EKXY": {
      "DOI": "10.48550/arXiv.2402.04559",
      "URL": "http://arxiv.org/abs/2402.04559",
      "abstract": "Large Language Model (LLM) agents have been increasingly adopted as simulation tools to model humans in applications such as social science. However, one fundamental question remains: can LLM agents really simulate human behaviors? In this paper, we focus on one of the most critical behaviors in human interactions, trust, and aim to investigate whether or not LLM agents can simulate human trust behaviors. We first find that LLM agents generally exhibit trust behaviors, referred to as agent trust, under the framework of Trust Games, which are widely recognized in behavioral economics. Then, we discover that LLM agents can have high behavioral alignment with humans regarding trust behaviors, particularly for GPT-4, indicating the feasibility to simulate human trust behaviors with LLM agents. In addition, we probe into the biases in agent trust and the differences in agent trust towards agents and humans. We also explore the intrinsic properties of agent trust under conditions including advanced reasoning strategies and external manipulations. We further offer important implications of our discoveries for various scenarios where trust is paramount. Our study provides new insights into the behaviors of LLM agents and the fundamental analogy between LLMs and humans.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Xie",
        "given": "Chengxing"
       },
       {
        "family": "Chen",
        "given": "Canyu"
       },
       {
        "family": "Jia",
        "given": "Feiran"
       },
       {
        "family": "Ye",
        "given": "Ziyu"
       },
       {
        "family": "Shu",
        "given": "Kai"
       },
       {
        "family": "Bibi",
        "given": "Adel"
       },
       {
        "family": "Hu",
        "given": "Ziniu"
       },
       {
        "family": "Torr",
        "given": "Philip"
       },
       {
        "family": "Ghanem",
        "given": "Bernard"
       },
       {
        "family": "Li",
        "given": "Guohao"
       }
      ],
      "id": "27937/I363EKXY",
      "issued": {
       "date-parts": [
        [
         2024,
         3,
         10
        ]
       ]
      },
      "note": "arXiv:2402.04559",
      "number": "arXiv:2402.04559",
      "publisher": "arXiv",
      "system_id": "zotero|27937/I363EKXY",
      "title": "Can Large Language Model Agents Simulate Human Trust Behaviors?",
      "type": "article"
     },
     "27937/IEQ8GAVU": {
      "ISBN": "9781479837243",
      "abstract": "A revealing look at how negative biases against women of color are embedded in search engine results and algorithms Run a Google search for “black girls”―what will you find? “Big Booty” and other sexually explicit terms are likely to come up as top search terms. But, if you type in “white girls,” the results are radically different. The suggested porn sites and un-moderated discussions about “why black women are so sassy” or “why black women are so angry” presents a disturbing portrait of black womanhood in modern society.In Algorithms of Oppression, Safiya Umoja Noble challenges the idea that search engines like Google offer an equal playing field for all forms of ideas, identities, and activities. Data discrimination is a real social problem; Noble argues that the combination of private interests in promoting certain sites, along with the monopoly status of a relatively small number of Internet search engines, leads to a biased set of search algorithms that privilege whiteness and discriminate against people of color, specifically women of color.Through an analysis of textual and media searches as well as extensive research on paid online advertising, Noble exposes a culture of racism and sexism in the way discoverability is created online. As search engines and their related companies grow in importance―operating as a source for email, a major vehicle for primary and secondary school learning, and beyond―understanding and reversing these disquieting trends and discriminatory practices is of utmost importance.An original, surprising and, at times, disturbing account of bias on the internet, Algorithms of Oppression contributes to our understanding of how racism is created, maintained, and disseminated in the 21st century.",
      "author": [
       {
        "family": "Noble",
        "given": "Safiya Umoja"
       }
      ],
      "edition": "Illustrated edition",
      "event-place": "New York",
      "id": "27937/IEQ8GAVU",
      "issued": {
       "date-parts": [
        [
         2018,
         2,
         20
        ]
       ]
      },
      "language": "English",
      "number-of-pages": "248",
      "publisher": "NYU Press",
      "publisher-place": "New York",
      "shortTitle": "Algorithms of Oppression",
      "system_id": "zotero|27937/IEQ8GAVU",
      "title": "Algorithms of Oppression: How Search Engines Reinforce Racism",
      "type": "book"
     },
     "27937/IJWETJM7": {
      "URL": "https://docsouth.unc.edu/sohp/A-0339/menu.html",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         31
        ]
       ]
      },
      "id": "27937/IJWETJM7",
      "system_id": "zotero|27937/IJWETJM7",
      "title": "John Hope Franklin and John Egerton, conducted by Oral History Interview with John Hope Franklin, July 27, 1990. Interview A-0339. Southern Oral History Program Collection (#4007).",
      "type": "webpage"
     },
     "27937/JV9GGCQA": {
      "URL": "https://huggingface.co/blog/Pclanglais/post-ocr-correction",
      "abstract": "A Blog post by Pierre-Carl Langlais on Hugging Face",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         14
        ]
       ]
      },
      "id": "27937/JV9GGCQA",
      "shortTitle": "Post-OCR-Correction",
      "system_id": "zotero|27937/JV9GGCQA",
      "title": "Post-OCR-Correction: 1 billion words dataset of automated OCR correction by LLM",
      "type": "webpage"
     },
     "27937/KKDPZJYW": {
      "DOI": "10.21437/Interspeech.2023-872",
      "URL": "https://www.isca-archive.org/interspeech_2023/lehecka23_interspeech.html",
      "abstract": "This paper is a step forward in our effort to make vast oral history archives more accessible to the public and researchers by breaking down the decoding barriers between the knowledge encoded in the spoken testimonies and users who want to search for the information of their interest. We present new Transformer-based monolingual models suitable for speech recognition of oral history archives in English, German, and Czech. Our experiments show that although the all-purpose speech recognition systems have recently made tremendous progress, the transcription of oral history archives is still a challenging task for them; our tailored models significantly outperformed larger public multilingual models and scored new stateof-the-art results on all tested datasets. Due to the 2-phase finetuning process, our models are robust and can be used for oral history archives of various domains. We publicly release our models within a public speech recognition service.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         10
        ]
       ]
      },
      "author": [
       {
        "family": "Lehečka",
        "given": "Jan"
       },
       {
        "family": "Švec",
        "given": "Jan"
       },
       {
        "family": "Psutka",
        "given": "Josef V."
       },
       {
        "family": "Ircing",
        "given": "Pavel"
       }
      ],
      "container-title": "INTERSPEECH 2023",
      "event": "INTERSPEECH 2023",
      "id": "27937/KKDPZJYW",
      "issued": {
       "date-parts": [
        [
         2023,
         8,
         20
        ]
       ]
      },
      "language": "en",
      "page": "201-205",
      "publisher": "ISCA",
      "system_id": "zotero|27937/KKDPZJYW",
      "title": "Transformer-based Speech Recognition Models for Oral History Archives in English, German, and Czech",
      "type": "paper-conference"
     },
     "27937/KNEK45E4": {
      "URL": "http://arxiv.org/abs/2005.14165",
      "abstract": "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         27
        ]
       ]
      },
      "author": [
       {
        "family": "Brown",
        "given": "Tom B."
       },
       {
        "family": "Mann",
        "given": "Benjamin"
       },
       {
        "family": "Ryder",
        "given": "Nick"
       },
       {
        "family": "Subbiah",
        "given": "Melanie"
       },
       {
        "family": "Kaplan",
        "given": "Jared"
       },
       {
        "family": "Dhariwal",
        "given": "Prafulla"
       },
       {
        "family": "Neelakantan",
        "given": "Arvind"
       },
       {
        "family": "Shyam",
        "given": "Pranav"
       },
       {
        "family": "Sastry",
        "given": "Girish"
       },
       {
        "family": "Askell",
        "given": "Amanda"
       },
       {
        "family": "Agarwal",
        "given": "Sandhini"
       },
       {
        "family": "Herbert-Voss",
        "given": "Ariel"
       },
       {
        "family": "Krueger",
        "given": "Gretchen"
       },
       {
        "family": "Henighan",
        "given": "Tom"
       },
       {
        "family": "Child",
        "given": "Rewon"
       },
       {
        "family": "Ramesh",
        "given": "Aditya"
       },
       {
        "family": "Ziegler",
        "given": "Daniel M."
       },
       {
        "family": "Wu",
        "given": "Jeffrey"
       },
       {
        "family": "Winter",
        "given": "Clemens"
       },
       {
        "family": "Hesse",
        "given": "Christopher"
       },
       {
        "family": "Chen",
        "given": "Mark"
       },
       {
        "family": "Sigler",
        "given": "Eric"
       },
       {
        "family": "Litwin",
        "given": "Mateusz"
       },
       {
        "family": "Gray",
        "given": "Scott"
       },
       {
        "family": "Chess",
        "given": "Benjamin"
       },
       {
        "family": "Clark",
        "given": "Jack"
       },
       {
        "family": "Berner",
        "given": "Christopher"
       },
       {
        "family": "McCandlish",
        "given": "Sam"
       },
       {
        "family": "Radford",
        "given": "Alec"
       },
       {
        "family": "Sutskever",
        "given": "Ilya"
       },
       {
        "family": "Amodei",
        "given": "Dario"
       }
      ],
      "id": "27937/KNEK45E4",
      "issued": {
       "date-parts": [
        [
         2020,
         7,
         22
        ]
       ]
      },
      "note": "arXiv:2005.14165 [cs]",
      "number": "arXiv:2005.14165",
      "publisher": "arXiv",
      "system_id": "zotero|27937/KNEK45E4",
      "title": "Language Models are Few-Shot Learners",
      "type": "article"
     },
     "27937/KPPP2BAQ": {
      "URL": "https://www.nbcnews.com/tech/tech-news/chatgpt-gpt-chat-bot-ai-hitler-historical-figures-open-rcna66531",
      "abstract": "The Historical Figures app is available in Apple's App Store and lets you chat with notable people from history re-animated by artificial intelligence.",
      "accessed": {
       "date-parts": [
        [
         2023,
         4,
         2
        ]
       ]
      },
      "container-title": "NBC News",
      "id": "27937/KPPP2BAQ",
      "issued": {
       "date-parts": [
        [
         2023,
         1,
         20
        ]
       ]
      },
      "language": "en",
      "system_id": "zotero|27937/KPPP2BAQ",
      "title": "Chatbot that lets you talk to Jesus and Hitler is latest AI controversy",
      "type": "webpage"
     },
     "27937/L2ILKERU": {
      "ISBN": "9781783266371",
      "abstract": "The Digital Humanities have arrived at a moment when digital Big Data is becoming more readily available, opening exciting new avenues of inquiry but also new challenges. This pioneering book describes and demonstrates the ways these data can be explored to construct cultural heritage knowledge, for research and in teaching and learning. It helps humanities scholars to grasp Big Data in order to do their work, whether that means understanding the underlying algorithms at work in search engines, or designing and using their own tools to process large amounts of information.Demonstrating what digital tools have to offer and also what 'digital' does to how we understand the past, the authors introduce the many different tools and developing approaches in Big Data for historical and humanistic scholarship, show how to use them, what to be wary of, and discuss the kinds of questions and new perspectives this new macroscopic perspective opens up. Authored 'live' online with ongoing feedback from the wider digital history community, Exploring Big Historical Data breaks new ground and sets the direction for the conversation into the future. It represents the current state-of-the-art thinking in the field and exemplifies the way that digital work can enhance public engagement in the humanities.Exploring Big Historical Data should be the go-to resource for undergraduate and graduate students confronted by a vast corpus of data, and researchers encountering these methods for the first time. It will also offer a helping hand to the interested individual seeking to make sense of genealogical data or digitized newspapers, and even the local historical society who are trying to see the value in digitizing their holdings.",
      "author": [
       {
        "family": "Graham",
        "given": "Shawn"
       },
       {
        "family": "Milligan",
        "given": "Ian"
       },
       {
        "family": "Weingart",
        "given": "Scott"
       }
      ],
      "edition": "Reprint edition",
      "event-place": "London",
      "id": "27937/L2ILKERU",
      "issued": {
       "date-parts": [
        [
         2015,
         11,
         16
        ]
       ]
      },
      "language": "English",
      "number-of-pages": "306",
      "publisher": "Icp",
      "publisher-place": "London",
      "shortTitle": "Exploring Big Historical Data",
      "system_id": "zotero|27937/L2ILKERU",
      "title": "Exploring Big Historical Data: The Historian's Macroscope",
      "type": "book"
     },
     "27937/LC63DETW": {
      "DOI": "10.1038/s41467-024-45563-x",
      "URL": "https://www.nature.com/articles/s41467-024-45563-x",
      "abstract": "Extracting structured knowledge from scientific text remains a challenging task for machine learning models. Here, we present a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models (GPT-3, Llama-2) can be fine-tuned to extract useful records of complex scientific knowledge. We test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks, and general composition/phase/morphology/application information extraction. Records are extracted from single sentences or entire paragraphs, and the output can be returned as simple English sentences or a more structured format such as a list of JSON objects. This approach represents a simple, accessible, and highly flexible route to obtaining large databases of structured specialized scientific knowledge extracted from research papers.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         15
        ]
       ]
      },
      "author": [
       {
        "family": "Dagdelen",
        "given": "John"
       },
       {
        "family": "Dunn",
        "given": "Alexander"
       },
       {
        "family": "Lee",
        "given": "Sanghoon"
       },
       {
        "family": "Walker",
        "given": "Nicholas"
       },
       {
        "family": "Rosen",
        "given": "Andrew S."
       },
       {
        "family": "Ceder",
        "given": "Gerbrand"
       },
       {
        "family": "Persson",
        "given": "Kristin A."
       },
       {
        "family": "Jain",
        "given": "Anubhav"
       }
      ],
      "container-title": "Nature Communications",
      "id": "27937/LC63DETW",
      "issue": "1",
      "issued": {
       "date-parts": [
        [
         2024,
         2,
         15
        ]
       ]
      },
      "journalAbbreviation": "Nat Commun",
      "language": "en",
      "note": "Publisher: Nature Publishing Group",
      "page": "1418",
      "system_id": "zotero|27937/LC63DETW",
      "title": "Structured information extraction from scientific text with large language models",
      "type": "article-journal",
      "volume": "15"
     },
     "27937/MHRIEHH8": {
      "URL": "http://arxiv.org/abs/2009.11462",
      "abstract": "Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning \"bad\" words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et. al, 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "author": [
       {
        "family": "Gehman",
        "given": "Samuel"
       },
       {
        "family": "Gururangan",
        "given": "Suchin"
       },
       {
        "family": "Sap",
        "given": "Maarten"
       },
       {
        "family": "Choi",
        "given": "Yejin"
       },
       {
        "family": "Smith",
        "given": "Noah A."
       }
      ],
      "id": "27937/MHRIEHH8",
      "issued": {
       "date-parts": [
        [
         2020,
         9,
         25
        ]
       ]
      },
      "note": "arXiv:2009.11462 [cs]",
      "number": "arXiv:2009.11462",
      "publisher": "arXiv",
      "shortTitle": "RealToxicityPrompts",
      "system_id": "zotero|27937/MHRIEHH8",
      "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models",
      "type": "article"
     },
     "27937/MVDFMR8K": {
      "URL": "https://dl.acm.org/doi/10.1145/3442188.3445922",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         27
        ]
       ]
      },
      "author": [
       {
        "family": "Bender",
        "given": "Emily"
       },
       {
        "family": "Gebru",
        "given": "Timnit"
       },
       {
        "family": "McMillan-Major",
        "given": "Angelina"
       },
       {
        "family": "Mitchell",
        "given": "Margaret"
       }
      ],
      "id": "27937/MVDFMR8K",
      "system_id": "zotero|27937/MVDFMR8K",
      "title": "On the Dangers of Stochastic Parrots | Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",
      "type": "webpage"
     },
     "27937/MYBFNHF8": {
      "URL": "https://lil.law.harvard.edu/blog/2024/02/12/warc-gpt-an-open-source-tool-for-exploring-web-archives-with-ai/",
      "abstract": "Today we’re releasing WARC-GPT: an open-source, highly-customizable Retrieval Augmented Generation tool the web archiving community can use to explore the in...",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "id": "27937/MYBFNHF8",
      "issued": {
       "date-parts": [
        [
         2024,
         2,
         12
        ]
       ]
      },
      "language": "en",
      "shortTitle": "WARC-GPT",
      "system_id": "zotero|27937/MYBFNHF8",
      "title": "WARC-GPT: An Open-Source Tool for Exploring Web Archives Using AI | Library Innovation Lab",
      "type": "webpage"
     },
     "27937/MYFQUX4C": {
      "URL": "https://www.rit.edu/news/artificial-intelligence-aids-cultural-heritage-researchers-documenting-and-teaching-oral",
      "abstract": "The application of artificial intelligence (AI) continues to expand as more people experiment with the technology. Scholars in RIT’s College of Liberal Arts, the RIT Archives, and the Research Computing services are exploring how AI can aid scholars working with oral histories.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         10
        ]
       ]
      },
      "container-title": "RIT",
      "id": "27937/MYFQUX4C",
      "language": "en",
      "system_id": "zotero|27937/MYFQUX4C",
      "title": "Artificial intelligence aids cultural heritage researchers documenting and teaching oral histories",
      "type": "webpage"
     },
     "27937/NYNDVYMM": {
      "URL": "https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business",
      "abstract": "OpenAI's language model, GPT-3, is being used in commercial products and services, but experts worry about embedded bias and toxic language generation",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "id": "27937/NYNDVYMM",
      "language": "en",
      "system_id": "zotero|27937/NYNDVYMM",
      "title": "OpenAI's GPT-3 Speaks! (Kindly Disregard Toxic Language) - IEEE Spectrum",
      "type": "webpage"
     },
     "27937/P2KVKTMZ": {
      "URL": "https://nicolay-honestabes-info.streamlit.app/",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "author": [
       {
        "family": "Hutchinson",
        "given": "Daniel"
       }
      ],
      "container-title": "Abraham Gibson, ed., Honest Abe’s Information Emporium.",
      "id": "27937/P2KVKTMZ",
      "issued": {
       "date-parts": [
        [
         2023
        ]
       ]
      },
      "system_id": "zotero|27937/P2KVKTMZ",
      "title": "Nicolay: Exploring the Speeches of Abraham Lincoln with AI",
      "type": "webpage"
     },
     "27937/QPK6D3M9": {
      "URL": "https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard",
      "abstract": "Track, rank and evaluate open LLMs and chatbots",
      "accessed": {
       "date-parts": [
        [
         2024,
         9,
         30
        ]
       ]
      },
      "id": "27937/QPK6D3M9",
      "system_id": "zotero|27937/QPK6D3M9",
      "title": "Open LLM Leaderboard 2 - a Hugging Face Space by open-llm-leaderboard",
      "type": "webpage"
     },
     "27937/R5P23ZWU": {
      "URL": "https://nebnewspapers.unl.edu/lccn/2017270209/1890-10-04/ed-1/seq-1/",
      "accessed": {
       "date-parts": [
        [
         2023,
         4,
         2
        ]
       ]
      },
      "id": "27937/R5P23ZWU",
      "system_id": "zotero|27937/R5P23ZWU",
      "title": "The farmers' alliance. (Lincoln, Nebraska) 1889-1892, October 04, 1890, Image 1 « Nebraska Newspapers",
      "type": "webpage"
     },
     "27937/RJTNQXZP": {
      "DOI": "10.48550/arXiv.2402.14207",
      "URL": "http://arxiv.org/abs/2402.14207",
      "abstract": "We study how to apply large language models to write grounded and organized long-form articles from scratch, with comparable breadth and depth to Wikipedia pages. This underexplored problem poses new challenges at the pre-writing stage, including how to research the topic and prepare an outline prior to writing. We propose STORM, a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking. STORM models the pre-writing stage by (1) discovering diverse perspectives in researching the given topic, (2) simulating conversations where writers carrying different perspectives pose questions to a topic expert grounded on trusted Internet sources, (3) curating the collected information to create an outline. For evaluation, we curate FreshWiki, a dataset of recent high-quality Wikipedia articles, and formulate outline assessments to evaluate the pre-writing stage. We further gather feedback from experienced Wikipedia editors. Compared to articles generated by an outline-driven retrieval-augmented baseline, more of STORM's articles are deemed to be organized (by a 25% absolute increase) and broad in coverage (by 10%). The expert feedback also helps identify new challenges for generating grounded long articles, such as source bias transfer and over-association of unrelated facts.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "author": [
       {
        "family": "Shao",
        "given": "Yijia"
       },
       {
        "family": "Jiang",
        "given": "Yucheng"
       },
       {
        "family": "Kanell",
        "given": "Theodore A."
       },
       {
        "family": "Xu",
        "given": "Peter"
       },
       {
        "family": "Khattab",
        "given": "Omar"
       },
       {
        "family": "Lam",
        "given": "Monica S."
       }
      ],
      "id": "27937/RJTNQXZP",
      "issued": {
       "date-parts": [
        [
         2024,
         4,
         8
        ]
       ]
      },
      "note": "arXiv:2402.14207",
      "number": "arXiv:2402.14207",
      "publisher": "arXiv",
      "system_id": "zotero|27937/RJTNQXZP",
      "title": "Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models",
      "type": "article"
     },
     "27937/RRLN9TF5": {
      "URL": "https://huggingface.co/spaces/uonlp/open_multilingual_llm_leaderboard",
      "abstract": "Discover amazing ML apps made by the community",
      "accessed": {
       "date-parts": [
        [
         2024,
         9,
         30
        ]
       ]
      },
      "id": "27937/RRLN9TF5",
      "system_id": "zotero|27937/RRLN9TF5",
      "title": "Open Multilingual Llm Leaderboard - a Hugging Face Space by uonlp",
      "type": "webpage"
     },
     "27937/S3ADX5DD": {
      "ISBN": "9780190067397",
      "URL": "https://doi.org/10.1093/oxfordhb/9780190067397.013.16",
      "abstract": "This chapter discusses the role of race and gender in artificial intelligence (AI). The rapid permeation of AI into society has not been accompanied by a thorough investigation of the sociopolitical issues that cause certain groups of people to be harmed rather than advantaged by it. For instance, recent studies have shown that commercial automated facial analysis systems have much higher error rates for dark-skinned women, while having minimal errors on light-skinned men. Moreover, a 2016 ProPublica investigation uncovered that machine learning–based tools that assess crime recidivism rates in the United States are biased against African Americans. Other studies show that natural language–processing tools trained on news articles exhibit societal biases. While many technical solutions have been proposed to alleviate bias in machine learning systems, a holistic and multifaceted approach must be taken. This includes standardization bodies determining what types of systems can be used in which scenarios, making sure that automated decision tools are created by people from diverse backgrounds, and understanding the historical and political factors that disadvantage certain groups who are subjected to these tools.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "author": [
       {
        "family": "Gebru",
        "given": "Timnit"
       }
      ],
      "container-title": "The Oxford Handbook of Ethics of AI",
      "editor": [
       {
        "family": "Dubber",
        "given": "Markus D."
       },
       {
        "family": "Pasquale",
        "given": "Frank"
       },
       {
        "family": "Das",
        "given": "Sunit"
       }
      ],
      "id": "27937/S3ADX5DD",
      "issued": {
       "date-parts": [
        [
         2020,
         7,
         9
        ]
       ]
      },
      "note": "DOI: 10.1093/oxfordhb/9780190067397.013.16",
      "page": "0",
      "publisher": "Oxford University Press",
      "system_id": "zotero|27937/S3ADX5DD",
      "title": "Race and Gender",
      "type": "chapter"
     },
     "27937/TGPDB8WX": {
      "DOI": "10.48550/arXiv.1706.03741",
      "URL": "http://arxiv.org/abs/1706.03741",
      "abstract": "For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than one percent of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any that have been previously learned from human feedback.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         1
        ]
       ]
      },
      "author": [
       {
        "family": "Christiano",
        "given": "Paul"
       },
       {
        "family": "Leike",
        "given": "Jan"
       },
       {
        "family": "Brown",
        "given": "Tom B."
       },
       {
        "family": "Martic",
        "given": "Miljan"
       },
       {
        "family": "Legg",
        "given": "Shane"
       },
       {
        "family": "Amodei",
        "given": "Dario"
       }
      ],
      "id": "27937/TGPDB8WX",
      "issued": {
       "date-parts": [
        [
         2023,
         2,
         17
        ]
       ]
      },
      "note": "arXiv:1706.03741 [cs, stat]",
      "number": "arXiv:1706.03741",
      "publisher": "arXiv",
      "system_id": "zotero|27937/TGPDB8WX",
      "title": "Deep reinforcement learning from human preferences",
      "type": "article"
     },
     "27937/TIAJYHF6": {
      "DOI": "10.1108/JD-07-2018-0114",
      "URL": "https://doi.org/10.1108/JD-07-2018-0114",
      "abstract": "Purpose An overview of the current use of handwritten text recognition (HTR) on archival manuscript material, as provided by the EU H2020 funded Transkribus platform. It explains HTR, demonstrates Transkribus, gives examples of use cases, highlights the affect HTR may have on scholarship, and evidences this turning point of the advanced use of digitised heritage content. The paper aims to discuss these issues. Design/methodology/approach This paper adopts a case study approach, using the development and delivery of the one openly available HTR platform for manuscript material. Findings Transkribus has demonstrated that HTR is now a useable technology that can be employed in conjunction with mass digitisation to generate accurate transcripts of archival material. Use cases are demonstrated, and a cooperative model is suggested as a way to ensure sustainability and scaling of the platform. However, funding and resourcing issues are identified. Research limitations/implications The paper presents results from projects: further user studies could be undertaken involving interviews, surveys, etc. Practical implications Only HTR provided via Transkribus is covered: however, this is the only publicly available platform for HTR on individual collections of historical documents at time of writing and it represents the current state-of-the-art in this field. Social implications The increased access to information contained within historical texts has the potential to be transformational for both institutions and individuals. Originality/value This is the first published overview of how HTR is used by a wide archival studies community, reporting and showcasing current application of handwriting technology in the cultural heritage sector.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         27
        ]
       ]
      },
      "author": [
       {
        "family": "Muehlberger",
        "given": "Guenter"
       },
       {
        "family": "Seaward",
        "given": "Louise"
       },
       {
        "family": "Terras",
        "given": "Melissa"
       },
       {
        "family": "Ares Oliveira",
        "given": "Sofia"
       },
       {
        "family": "Bosch",
        "given": "Vicente"
       },
       {
        "family": "Bryan",
        "given": "Maximilian"
       },
       {
        "family": "Colutto",
        "given": "Sebastian"
       },
       {
        "family": "Déjean",
        "given": "Hervé"
       },
       {
        "family": "Diem",
        "given": "Markus"
       },
       {
        "family": "Fiel",
        "given": "Stefan"
       },
       {
        "family": "Gatos",
        "given": "Basilis"
       },
       {
        "family": "Greinoecker",
        "given": "Albert"
       },
       {
        "family": "Grüning",
        "given": "Tobias"
       },
       {
        "family": "Hackl",
        "given": "Guenter"
       },
       {
        "family": "Haukkovaara",
        "given": "Vili"
       },
       {
        "family": "Heyer",
        "given": "Gerhard"
       },
       {
        "family": "Hirvonen",
        "given": "Lauri"
       },
       {
        "family": "Hodel",
        "given": "Tobias"
       },
       {
        "family": "Jokinen",
        "given": "Matti"
       },
       {
        "family": "Kahle",
        "given": "Philip"
       },
       {
        "family": "Kallio",
        "given": "Mario"
       },
       {
        "family": "Kaplan",
        "given": "Frederic"
       },
       {
        "family": "Kleber",
        "given": "Florian"
       },
       {
        "family": "Labahn",
        "given": "Roger"
       },
       {
        "family": "Lang",
        "given": "Eva Maria"
       },
       {
        "family": "Laube",
        "given": "Sören"
       },
       {
        "family": "Leifert",
        "given": "Gundram"
       },
       {
        "family": "Louloudis",
        "given": "Georgios"
       },
       {
        "family": "McNicholl",
        "given": "Rory"
       },
       {
        "family": "Meunier",
        "given": "Jean-Luc"
       },
       {
        "family": "Michael",
        "given": "Johannes"
       },
       {
        "family": "Mühlbauer",
        "given": "Elena"
       },
       {
        "family": "Philipp",
        "given": "Nathanael"
       },
       {
        "family": "Pratikakis",
        "given": "Ioannis"
       },
       {
        "family": "Puigcerver Pérez",
        "given": "Joan"
       },
       {
        "family": "Putz",
        "given": "Hannelore"
       },
       {
        "family": "Retsinas",
        "given": "George"
       },
       {
        "family": "Romero",
        "given": "Verónica"
       },
       {
        "family": "Sablatnig",
        "given": "Robert"
       },
       {
        "family": "Sánchez",
        "given": "Joan Andreu"
       },
       {
        "family": "Schofield",
        "given": "Philip"
       },
       {
        "family": "Sfikas",
        "given": "Giorgos"
       },
       {
        "family": "Sieber",
        "given": "Christian"
       },
       {
        "family": "Stamatopoulos",
        "given": "Nikolaos"
       },
       {
        "family": "Strauß",
        "given": "Tobias"
       },
       {
        "family": "Terbul",
        "given": "Tamara"
       },
       {
        "family": "Toselli",
        "given": "Alejandro Héctor"
       },
       {
        "family": "Ulreich",
        "given": "Berthold"
       },
       {
        "family": "Villegas",
        "given": "Mauricio"
       },
       {
        "family": "Vidal",
        "given": "Enrique"
       },
       {
        "family": "Walcher",
        "given": "Johanna"
       },
       {
        "family": "Weidemann",
        "given": "Max"
       },
       {
        "family": "Wurster",
        "given": "Herbert"
       },
       {
        "family": "Zagoris",
        "given": "Konstantinos"
       }
      ],
      "container-title": "Journal of Documentation",
      "id": "27937/TIAJYHF6",
      "issue": "5",
      "issued": {
       "date-parts": [
        [
         2019,
         1,
         1
        ]
       ]
      },
      "page": "954-976",
      "shortTitle": "Transforming scholarship in the archives through handwritten text recognition",
      "system_id": "zotero|27937/TIAJYHF6",
      "title": "Transforming scholarship in the archives through handwritten text recognition: Transkribus as a case study",
      "type": "article-journal",
      "volume": "75"
     },
     "27937/TPGPSRAI": {
      "URL": "https://medium.com/@emilymenonbender/on-nyt-magazine-on-ai-resist-the-urge-to-be-impressed-3d92fd9a0edd",
      "abstract": "[Now available as an “audiopaper” on my soundcloud. (Please excuse occasional noise from airplanes overhead + my inconsistency about…",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "author": [
       {
        "family": "Bender",
        "given": "Emily M."
       }
      ],
      "container-title": "Medium",
      "id": "27937/TPGPSRAI",
      "issued": {
       "date-parts": [
        [
         2022,
         5,
         2
        ]
       ]
      },
      "language": "en",
      "shortTitle": "On NYT Magazine on AI",
      "system_id": "zotero|27937/TPGPSRAI",
      "title": "On NYT Magazine on AI: Resist the Urge to be Impressed",
      "type": "post-weblog"
     },
     "27937/U534FF7L": {
      "URL": "http://arxiv.org/abs/2303.08774",
      "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "author": [
       {
        "family": "OpenAI",
        "given": ""
       }
      ],
      "id": "27937/U534FF7L",
      "issued": {
       "date-parts": [
        [
         2023,
         3,
         27
        ]
       ]
      },
      "note": "arXiv:2303.08774 [cs]",
      "number": "arXiv:2303.08774",
      "publisher": "arXiv",
      "system_id": "zotero|27937/U534FF7L",
      "title": "GPT-4 Technical Report",
      "type": "article"
     },
     "27937/UHZYQM3W": {
      "URL": "https://www.newyorker.com/tech/annals-of-technology/whispers-of-ais-modular-future",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         10
        ]
       ]
      },
      "author": [
       {
        "family": "Somers",
        "given": "James"
       }
      ],
      "id": "27937/UHZYQM3W",
      "issued": {
       "date-parts": [
        [
         2023,
         2,
         1
        ]
       ]
      },
      "system_id": "zotero|27937/UHZYQM3W",
      "title": "Whispers of A.I.’s Modular Future | The New Yorker",
      "type": "webpage"
     },
     "27937/UYVGUT4C": {
      "URL": "http://arxiv.org/abs/2103.00020",
      "abstract": "State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "author": [
       {
        "family": "Radford",
        "given": "Alec"
       },
       {
        "family": "Kim",
        "given": "Jong Wook"
       },
       {
        "family": "Hallacy",
        "given": "Chris"
       },
       {
        "family": "Ramesh",
        "given": "Aditya"
       },
       {
        "family": "Goh",
        "given": "Gabriel"
       },
       {
        "family": "Agarwal",
        "given": "Sandhini"
       },
       {
        "family": "Sastry",
        "given": "Girish"
       },
       {
        "family": "Askell",
        "given": "Amanda"
       },
       {
        "family": "Mishkin",
        "given": "Pamela"
       },
       {
        "family": "Clark",
        "given": "Jack"
       },
       {
        "family": "Krueger",
        "given": "Gretchen"
       },
       {
        "family": "Sutskever",
        "given": "Ilya"
       }
      ],
      "id": "27937/UYVGUT4C",
      "issued": {
       "date-parts": [
        [
         2021,
         2,
         26
        ]
       ]
      },
      "note": "arXiv:2103.00020 [cs]",
      "number": "arXiv:2103.00020",
      "publisher": "arXiv",
      "system_id": "zotero|27937/UYVGUT4C",
      "title": "Learning Transferable Visual Models From Natural Language Supervision",
      "type": "article"
     },
     "27937/VEDFUUBA": {
      "URL": "http://arxiv.org/abs/2303.13375",
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets. GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks. Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States. We also evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications like medicine. Our results show that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). In addition, GPT-4 is significantly better calibrated than GPT-3.5, demonstrating a much-improved ability to predict the likelihood that its answers are correct. We also explore the behavior of the model qualitatively through a case study that shows the ability of GPT-4 to explain medical reasoning, personalize explanations to students, and interactively craft new counterfactual scenarios around a medical case. Implications of the findings are discussed for potential uses of GPT-4 in medical education, assessment, and clinical practice, with appropriate attention to challenges of accuracy and safety.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "author": [
       {
        "family": "Nori",
        "given": "Harsha"
       },
       {
        "family": "King",
        "given": "Nicholas"
       },
       {
        "family": "McKinney",
        "given": "Scott Mayer"
       },
       {
        "family": "Carignan",
        "given": "Dean"
       },
       {
        "family": "Horvitz",
        "given": "Eric"
       }
      ],
      "id": "27937/VEDFUUBA",
      "issued": {
       "date-parts": [
        [
         2023,
         3,
         20
        ]
       ]
      },
      "note": "arXiv:2303.13375 [cs]",
      "number": "arXiv:2303.13375",
      "publisher": "arXiv",
      "system_id": "zotero|27937/VEDFUUBA",
      "title": "Capabilities of GPT-4 on Medical Challenge Problems",
      "type": "article"
     },
     "27937/VHJBTADE": {
      "ISBN": "978-1-324-09112-7",
      "abstract": "\"A brilliant, revelatory account of the Cold War origins of the data-mad, algorithmic twenty-first century, from the author of the acclaimed international bestseller, These Truths. The Simulmatics Corporation, founded in 1959, mined data, targeted voters, accelerated news, manipulated consumers, destabilized politics, and disordered knowledge--decades before Facebook, Google, Amazon, and Cambridge Analytica. Silicon Valley likes to imagine it has no past but the scientists of Simulmatics are the long-dead grandfathers of Mark Zuckerberg and Elon Musk. Borrowing from psychological warfare, they used computers to predict and direct human behavior, deploying their \"People Machine\" from New York, Cambridge, and Saigon for clients that included John Kennedy's presidential campaign, the New York Times, Young & Rubicam, and, during the Vietnam War, the Department of Defense. Jill Lepore, distinguished Harvard historian and New Yorker staff writer, unearthed from the archives the almost unbelievable story of this long-vanished corporation, and of the women hidden behind it. In the 1950s and 1960s, Lepore argues, Simulmatics invented the future by building the machine in which the world now finds itself trapped and tormented, algorithm by algorithm\"-- Provided by publisher",
      "author": [
       {
        "family": "Lepore",
        "given": "Jill"
       }
      ],
      "event-place": "New York, NY",
      "id": "27937/VHJBTADE",
      "issued": {
       "date-parts": [
        [
         2021
        ]
       ]
      },
      "language": "eng",
      "note": "OCLC: 1233267158",
      "number-of-pages": "415",
      "publisher": "Liveright Publishing Corporation, a division of W.W. Norton & Company",
      "publisher-place": "New York, NY",
      "shortTitle": "If then",
      "system_id": "zotero|27937/VHJBTADE",
      "title": "If then: how the Simulmatics Corporation invented the future",
      "type": "book"
     },
     "27937/VXGSAGTI": {
      "ISBN": "9780471268512",
      "abstract": "Written for practitioners of data mining, data cleaning and database management.Presents a technical treatment of data quality including process, metrics, tools and algorithms.Focuses on developing an evolving modeling strategy through an iterative data exploration loop and incorporation of domain knowledge.Addresses methods of detecting, quantifying and correcting data quality issues that can have a significant impact on findings and decisions, using commercially available tools as well as new algorithmic approaches.Uses case studies to illustrate applications in real life scenarios.Highlights new approaches and methodologies, such as the DataSphere space partitioning and summary based analysis techniques.Exploratory Data Mining and Data Cleaning will serve as an important reference for serious data analysts who need to analyze large amounts of unfamiliar data, managers of operations databases, and students in undergraduate or graduate level courses dealing with large scale data analys is and data mining.",
      "author": [
       {
        "family": "Dasu",
        "given": "Tamraparni"
       },
       {
        "family": "Johnson",
        "given": "Theodore"
       }
      ],
      "edition": "1st edition",
      "event-place": "New York",
      "id": "27937/VXGSAGTI",
      "issued": {
       "date-parts": [
        [
         2003,
         5,
         9
        ]
       ]
      },
      "language": "English",
      "number-of-pages": "224",
      "publisher": "Wiley-Interscience",
      "publisher-place": "New York",
      "system_id": "zotero|27937/VXGSAGTI",
      "title": "Exploratory Data Mining and Data Cleaning",
      "type": "book"
     },
     "27937/X4D92B7V": {
      "ISBN": "9781509526406",
      "abstract": "From everyday apps to complex algorithms, Ruha Benjamin cuts through tech-industry hype to understand how emerging technologies can reinforce White supremacy and deepen social inequity.Benjamin argues that automation, far from being a sinister story of racist programmers scheming on the dark web, has the potential to hide, speed up, and deepen discrimination while appearing neutral and even benevolent when compared to the racism of a previous era. Presenting the concept of the “New Jim Code,” she shows how a range of discriminatory designs encode inequity by explicitly amplifying racial hierarchies; by ignoring but thereby replicating social divisions; or by aiming to fix racial bias but ultimately doing quite the opposite. Moreover, she makes a compelling case for race itself as a kind of technology, designed to stratify and sanctify social injustice in the architecture of everyday life.This illuminating guide provides conceptual tools for decoding tech promises with sociologically informed skepticism. In doing so, it challenges us to question not only the technologies we are sold but also the ones we ourselves manufacture.",
      "author": [
       {
        "family": "Benjamin",
        "given": "Ruha"
       }
      ],
      "edition": "1st edition",
      "event-place": "Medford, MA",
      "id": "27937/X4D92B7V",
      "issued": {
       "date-parts": [
        [
         2019,
         6,
         17
        ]
       ]
      },
      "language": "English",
      "number-of-pages": "172",
      "publisher": "Polity",
      "publisher-place": "Medford, MA",
      "shortTitle": "Race After Technology",
      "system_id": "zotero|27937/X4D92B7V",
      "title": "Race After Technology: Abolitionist Tools for the New Jim Code",
      "type": "book"
     },
     "27937/XBWIZZJJ": {
      "URL": "http://arxiv.org/abs/2304.03442",
      "abstract": "Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture--observation, planning, and reflection--each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         23
        ]
       ]
      },
      "author": [
       {
        "family": "Park",
        "given": "Joon Sung"
       },
       {
        "family": "O'Brien",
        "given": "Joseph C."
       },
       {
        "family": "Cai",
        "given": "Carrie J."
       },
       {
        "family": "Morris",
        "given": "Meredith Ringel"
       },
       {
        "family": "Liang",
        "given": "Percy"
       },
       {
        "family": "Bernstein",
        "given": "Michael S."
       }
      ],
      "id": "27937/XBWIZZJJ",
      "issued": {
       "date-parts": [
        [
         2023,
         8,
         6
        ]
       ]
      },
      "note": "arXiv:2304.03442",
      "number": "arXiv:2304.03442",
      "publisher": "arXiv",
      "shortTitle": "Generative Agents",
      "system_id": "zotero|27937/XBWIZZJJ",
      "title": "Generative Agents: Interactive Simulacra of Human Behavior",
      "type": "article"
     },
     "27937/XEUKQDPE": {
      "DOI": "10.18637/jss.v059.i10",
      "URL": "https://doi.org/10.18637/jss.v059.i10",
      "abstract": "A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         28
        ]
       ]
      },
      "author": [
       {
        "family": "Wickham",
        "given": "Hadley"
       }
      ],
      "container-title": "Journal of Statistical Software",
      "id": "27937/XEUKQDPE",
      "issued": {
       "date-parts": [
        [
         2014,
         9,
         12
        ]
       ]
      },
      "language": "en",
      "page": "1-23",
      "system_id": "zotero|27937/XEUKQDPE",
      "title": "Tidy Data",
      "type": "article-journal",
      "volume": "59"
     },
     "27937/XQYUJV5F": {
      "DOI": "10.1093/ahr/rhad362",
      "URL": "https://academic.oup.com/ahr/article/128/3/1345/7282240",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         25
        ]
       ]
      },
      "author": [
       {
        "family": "Meadows",
        "given": "R. Darrell"
       },
       {
        "family": "Sternfeld",
        "given": "Joshua"
       }
      ],
      "container-title": "The American Historical Review",
      "id": "27937/XQYUJV5F",
      "issue": "3",
      "issued": {
       "date-parts": [
        [
         2023,
         9,
         26
        ]
       ]
      },
      "language": "en",
      "page": "1345-1349",
      "system_id": "zotero|27937/XQYUJV5F",
      "title": "Artificial Intelligence and the Practice of History",
      "type": "article-journal",
      "volume": "128"
     },
     "27937/YVTAGDKZ": {
      "ISBN": "9780300209570",
      "abstract": "The hidden costs of artificial intelligence—from natural resources and labor to privacy, equality, and freedom\"This study argues that [artificial intelligence] is neither artificial nor particularly intelligent. . . . A fascinating history of the data on which machine-learning systems are trained.\"—New Yorker\"A valuable corrective to much of the hype surrounding AI and a useful instruction manual for the future.\"—John Thornhill, Financial Times\"It’s a masterpiece, and I haven’t been able to stop thinking about it.\"—Karen Hao, senior editor, MIT Tech Review What happens when artificial intelligence saturates political life and depletes the planet? How is AI shaping our understanding of ourselves and our societies? Drawing on more than a decade of research, award‑winning scholar Kate Crawford reveals how AI is a technology of extraction: from the minerals drawn from the earth, to the labor pulled from low-wage information workers, to the data taken from every action and expression. This book reveals how this planetary network is fueling a shift toward undemocratic governance and increased inequity. Rather than taking a narrow focus on code and algorithms, Crawford offers us a material and political perspective on what it takes to make AI and how it centralizes power. This is an urgent account of what is at stake as technology companies use artificial intelligence to reshape the world.",
      "author": [
       {
        "family": "Crawford",
        "given": "Kate"
       }
      ],
      "event-place": "New Haven",
      "id": "27937/YVTAGDKZ",
      "issued": {
       "date-parts": [
        [
         2021,
         4,
         6
        ]
       ]
      },
      "language": "English",
      "number-of-pages": "336",
      "publisher": "Yale University Press",
      "publisher-place": "New Haven",
      "shortTitle": "Atlas of AI",
      "system_id": "zotero|27937/YVTAGDKZ",
      "title": "Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence",
      "type": "book"
     },
     "27937/YWJAQ4V8": {
      "ISBN": "978-0-19-803513-8",
      "abstract": "Oral history is vital to our understanding of the cultures and experiences of the past. Unlike written history, oral history forever captures people's feelings, expressions, and nuances of language. But what exactly is oral history? How reliable is the information gathered by oral history? And what does it take to become an oral historian? Donald A. Ritchie, a leading expert in the field, answers these questions and in particular, explains the principles and guidelines created by the Oral History Association to ensure the professional standards of oral historians. Doing Oral History has becom",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         9
        ]
       ]
      },
      "author": [
       {
        "family": "Ritchie",
        "given": "Donald A."
       }
      ],
      "edition": "2nd ed",
      "event-place": "Cary",
      "id": "27937/YWJAQ4V8",
      "issued": {
       "date-parts": [
        [
         2003
        ]
       ]
      },
      "language": "eng",
      "note": "OCLC: 1049804116",
      "number-of-pages": "290",
      "publisher": "Oxford University Press, USA",
      "publisher-place": "Cary",
      "shortTitle": "Doing Oral History",
      "system_id": "zotero|27937/YWJAQ4V8",
      "title": "Doing Oral History: a Practical Guide",
      "type": "book"
     },
     "27937/YZQEASUC": {
      "URL": "https://aiandwriting.hcommons.org/",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         23
        ]
       ]
      },
      "id": "27937/YZQEASUC",
      "language": "en-US",
      "system_id": "zotero|27937/YZQEASUC",
      "title": "MLA-CCCC Joint Task Force on Writing and AI",
      "type": "post-weblog"
     },
     "27937/Z44J4BKC": {
      "DOI": "10.1093/jamia/ocad259",
      "URL": "https://doi.org/10.1093/jamia/ocad259",
      "abstract": "The study highlights the potential of large language models, specifically GPT-3.5 and GPT-4, in processing complex clinical data and extracting meaningful information with minimal training data. By developing and refining prompt-based strategies, we can significantly enhance the models’ performance, making them viable tools for clinical NER tasks and possibly reducing the reliance on extensive annotated datasets.This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance.We evaluated these models on 2 clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) to identify nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT.Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all 4 components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed.The study’s findings suggest a promising direction in leveraging LLMs for clinical NER tasks. However, while the performance of GPT models improved with task-specific prompts, there's a need for further development and refinement. LLMs like GPT-4 show potential in achieving close performance to state-of-the-art models like BioClinicalBERT, but they still require careful prompt engineering and understanding of task-specific knowledge. The study also underscores the importance of evaluation schemas that accurately reflect the capabilities and performance of LLMs in clinical settings.While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         16
        ]
       ]
      },
      "author": [
       {
        "family": "Hu",
        "given": "Yan"
       },
       {
        "family": "Chen",
        "given": "Qingyu"
       },
       {
        "family": "Du",
        "given": "Jingcheng"
       },
       {
        "family": "Peng",
        "given": "Xueqing"
       },
       {
        "family": "Keloth",
        "given": "Vipina Kuttichi"
       },
       {
        "family": "Zuo",
        "given": "Xu"
       },
       {
        "family": "Zhou",
        "given": "Yujia"
       },
       {
        "family": "Li",
        "given": "Zehan"
       },
       {
        "family": "Jiang",
        "given": "Xiaoqian"
       },
       {
        "family": "Lu",
        "given": "Zhiyong"
       },
       {
        "family": "Roberts",
        "given": "Kirk"
       },
       {
        "family": "Xu",
        "given": "Hua"
       }
      ],
      "container-title": "Journal of the American Medical Informatics Association",
      "id": "27937/Z44J4BKC",
      "issue": "9",
      "issued": {
       "date-parts": [
        [
         2024,
         9,
         1
        ]
       ]
      },
      "journalAbbreviation": "Journal of the American Medical Informatics Association",
      "page": "1812-1820",
      "system_id": "zotero|27937/Z44J4BKC",
      "title": "Improving large language models for clinical named entity recognition via prompt engineering",
      "type": "article-journal",
      "volume": "31"
     },
     "27937/ZICATXAV": {
      "URL": "https://gradio.app/",
      "accessed": {
       "date-parts": [
        [
         2024,
         9,
         30
        ]
       ]
      },
      "id": "27937/ZICATXAV",
      "language": "en-US",
      "shortTitle": "Chatbot Arena (formerly LMSYS)",
      "system_id": "zotero|27937/ZICATXAV",
      "title": "Chatbot Arena (formerly LMSYS): Free AI Chat to Compare & Test Best AI Chatbots",
      "type": "webpage"
     },
     "27937/ZJW9AI49": {
      "DOI": "10.3138/chr.694",
      "URL": "https://www.utpjournals.press/doi/abs/10.3138/chr.694",
      "abstract": "It all seems so orderly and comprehensive. Instead of firing up the microfilm reader to navigate the Globe and Mail or the Toronto Star, one needs only to log into online newspaper databases. A keyword search, for a particular event, person, or cultural phenomenon, brings up a list of research findings. Previously impossible research projects can now be attempted. This process has fundamentally reshaped Canadian historical scholarship. We can see this in Canadian history dissertations. In 1998, a year with 67 dissertations, the Toronto Star was cited 74 times. However it was cited 753 times in 2010, a year with 69 dissertations. Similar data appears in the Canadian Historical Review (CHR), a prestigious peer-reviewed journal. Databases are skewing our research. We are witnessing the application of commercial Optical Character Recognition (OCR) technology – originally and primarily designed for the efficient digitization of large reams of corporate and legal documents, conventionally formatted – to historical sources. The results are, unsurprisingly, a mixed bag. In this article, I make two arguments. Firstly, online historical databases have profoundly shaped Canadian historiography. In a shift that is rarely – if ever – made explicit, Canadian historians have profoundly reacted to the availability of online databases. Secondly, historians need to understand how OCR works, in order to bring a level of methodological rigor to their work that use these sources.",
      "accessed": {
       "date-parts": [
        [
         2023,
         3,
         31
        ]
       ]
      },
      "author": [
       {
        "family": "Milligan",
        "given": "Ian"
       }
      ],
      "container-title": "Canadian Historical Review",
      "id": "27937/ZJW9AI49",
      "issue": "4",
      "issued": {
       "date-parts": [
        [
         2013,
         12
        ]
       ]
      },
      "page": "540-569",
      "shortTitle": "Illusionary Order",
      "system_id": "zotero|27937/ZJW9AI49",
      "title": "Illusionary Order: Online Databases, Optical Character Recognition, and Canadian History, 1997–2010",
      "type": "article-journal",
      "volume": "94"
     },
     "27937/ZS9JDNGD": {
      "URL": "http://arxiv.org/abs/2009.03300",
      "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
      "accessed": {
       "date-parts": [
        [
         2023,
         4,
         2
        ]
       ]
      },
      "author": [
       {
        "family": "Hendrycks",
        "given": "Dan"
       },
       {
        "family": "Burns",
        "given": "Collin"
       },
       {
        "family": "Basart",
        "given": "Steven"
       },
       {
        "family": "Zou",
        "given": "Andy"
       },
       {
        "family": "Mazeika",
        "given": "Mantas"
       },
       {
        "family": "Song",
        "given": "Dawn"
       },
       {
        "family": "Steinhardt",
        "given": "Jacob"
       }
      ],
      "id": "27937/ZS9JDNGD",
      "issued": {
       "date-parts": [
        [
         2021,
         1,
         12
        ]
       ]
      },
      "note": "arXiv:2009.03300 [cs]",
      "number": "arXiv:2009.03300",
      "publisher": "arXiv",
      "system_id": "zotero|27937/ZS9JDNGD",
      "title": "Measuring Massive Multitask Language Understanding",
      "type": "article"
     },
     "27937/ZXTQBIJU": {
      "URL": "https://huggingface.co/datasets/PleIAs/Post-OCR-Correction",
      "abstract": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
      "accessed": {
       "date-parts": [
        [
         2024,
         10,
         14
        ]
       ]
      },
      "id": "27937/ZXTQBIJU",
      "issued": {
       "date-parts": [
        [
         2024,
         6,
         9
        ]
       ]
      },
      "system_id": "zotero|27937/ZXTQBIJU",
      "title": "PleIAs/Post-OCR-Correction · Datasets at Hugging Face",
      "type": "webpage"
     }
    }
   },
   "style": "chicago-note-bibliography.csl"
  },
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
